{"author":"","clickNumber":0,"content":"\r\n<div class=\"ibm-columns\">\r\n<div class=\"ibm-col-1-1\">\r\n\r\n<p>每个人都在谈论虚拟化。根据宣传，虚拟化将引发 IT 革命（众所周知），优化稀缺资源，并节省每个人的钱。服务器虚拟化有望成为 10 年内最重要的发展之一。但是，虚拟化已经存在了很长时间，而且 IBM 已借助 IBM&#174; System z&#174; 和 Power Systems&#8482; 平台成为这一领域的领导者。在过去几年中，System x&#174; 和基于 Intel 的 x86 架构上的虚拟化技术已发展成熟并变得更加普遍。只要使用得当，虚拟化是 IT 工具箱中一个不可或缺的部分。毋庸置疑，虚拟化已有牢固的根基。<\/p><p>但每种技术都存在风险。管理不良的虚拟化可能导致应用程序运行得更慢，这可能导致最终用户厌烦和不满。IBM 为其部署在虚拟化环境中的产品提供了全面支持。或许由于它的普遍性和诱人的承诺，我们看到客户深受管理不良的虚拟化环境所害，导致他们未能获得任何承诺的收益。<\/p><p>这个由两部分组成的文章系列将通过具体示例探讨虚拟化的优缺点。在第 1 部分中，我们将从总体上解释虚拟化，尤其是它与 IBM Rational 软件的关系。我们将讨论管理良好的虚拟化环境的主要要求，展示 IBM&#174; Rational&#174; ClearCase&#174; 和 IBM&#174; Rational Team Concert&#8482; 在配置不良的虚拟化环境中的行为的示例。我们将提供正确管理虚拟化基础架构的建议和技巧，总结我们测试 Rational 软件和为客户提供咨询的经验。<\/p><p>第 2 部分将继续讨论建议和技巧，包括故障排除和特定于供应商的示例。<\/p><div class=\"dw-sidebar ibm-inset\"><h2 id=\"N10094\">虚拟化的简史<\/h2><p>尽管在过去几年，服务器虚拟化以一种富有吸引力的必要技术的形式出现，但它实际上已经存在了很久。上世纪 90 年代，IBM 在 System z 和 System i&#174; 产品线中引入了虚拟机管理程序技术。2000 年，在 System p&#174; 上实现了逻辑分区 (LPAR)。早在 1999 年，就已经在 System x 和基于 Intel 的 x86 硬件上实现了虚拟机。但仅在最近几年，虚拟化才开始在 Microsoft Windows 和 Linux 环境中变得不可或缺。<\/p><\/div><h2 id=\"1.Cloudsintheforecast|outline\">关于云的预测<\/h2><p>虚拟化通常与云技术密不可分。认识二者的关系至关重要。最宽泛地讲，云技术致力于以服务的形式提供服务器功能。虚拟化是一项管理提供该功能的服务器资源的关键技术。<\/p><p>我们还需要区分公有云和私有云。简单地讲，私有云是隔离的，可在一个公司内管理和托管，有时也可以在外部管理和托管。私有云受防火墙、身份验证、VPN\n                等保护。公有云通常没有这么安全，可以高效地由任何人共享和访问。许多流行的公共服务都是 “在云中” 提供的，比如电子邮件、文件和照片存储。公有云模型吸引了一些组织，因为在理论上，组织或个人仅需要为他们所需的内容付费，服务始终可在任何地方享受，而且云提供商处理了大部分 IT 管理任务。<\/p><p>我们发现，一些 IBM Rational 客户对公有云环境的不稳定性和安全问题呲之以鼻。他们喜欢在内部托管、管理更紧密的私有云方法，在这里，他们可以控制服务器资源分配的所有方面，设置特定的服务质量目标，并采用成熟的高可用性和灾难恢复解决方案。<\/p><p>但是，一些客户喜欢基于 IBM 云的解决方案，因为它们是使用软件开发和托管战略最佳实践来设计和管理的。IBM 也在私有云中提供了 Rational 软件。（参见 <a href=\"#resources\">参考资料<\/a> 部分，获取这些选项的更多信息。）<\/p><h2 id=\"2.Basicconcepts|outline\">基本概念<\/h2><p>简单地讲，虚拟化允许将一个较大的服务器（主机或虚拟机管理程序）分割为更小的服务器（Guest、客户端或虚拟机），并共享组合的资源池。众所周知，大多数服务器都不会始终以全容量运行。因此，为什么不共享和组合它们？两个平均剩余 25% 的容量的服务器可变成虚拟机 (VM) 并托管在单个虚拟机管理程序上，这样该虚拟机管理程序就拥有平均大约 50% 的容量。当然，主机操作系统和虚拟机管理程序软件占用了大量的开销，而且还涉及到其他细节。<\/p><p>主机通过软件或模拟来管理客户端的资源。一般而言，虚拟机中没有任何信息能表明它实际上是虚拟的。在大多数情况下，在虚拟机上安装软件的管理员无法确定他们是否在使用虚拟服务器。最新的创新，比如内置于虚拟机管理程序的芯片组中的虚拟化技术，允许更准确地使用优化过的方式来处理硬件资源，比如外围设备驱动程序。<\/p><h2 id=\"3.TheRationalperspectiveonvirtualization|outline\">Rational 视角下的虚拟化<\/h2><p>IBM <a href=\"http://www-01.ibm.com/software/support/virtualization_policy.html\">支持虚拟化<\/a>，因此 IBM Rational 产品受虚拟化的服务器支持。但是，我们坚信虚拟化的基础架构可适当地进行管理和监视。至关重要的是理解您的虚拟化基础架构如何使用<strong>关联性 (affinity)<\/strong> 和<strong>过度承诺 (overcommitment)<\/strong>，而且还要确保您使用关联性和过度承诺的方式可获得 IBM Rational 软件的最佳性能。<\/p><h3 id=\"3.1.Whatisthisthingcalledaffinity?|outline\">何为 “关联性”？<\/h3><p><strong>关联性（Affinity）<\/strong>（也称为<em>entitlement<\/em>、<em>pinning<\/em> 和<em>dedication<\/em>）是将一个虚拟机上的一种或多种资源（例如内存或处理器）专门用于虚拟机管理程序上的相应资源的能力。主机会在虚拟机需要时分配资源。关联性可确保专用于该虚拟机的已请求资源在虚拟机需要时始终可用。<\/p><p>请记住，相同主机上的所有虚拟机都会共享系统资源。<\/p><p><strong>过度承诺<\/strong> 是指虚拟镜像资源分配总量超过硬件的物理资源（一定要计算虚拟机资源）。为了满足虚拟机的峰值需求，虚拟机管理程序可从其他虚拟机获取资源。有时，所有虚拟机的组合需求可能超过虚拟机管理程序的实际资源量。有时，过度承诺可能导致主机上的所有虚拟机都受到影响。<\/p><h2 id=\"4.Virtualization'sfourdimensions|outline\">虚拟化的 4 个维度<\/h2><p>与任何可配置的技术一样，虚拟化也需要进行权衡。从 Rational 产品角度讲，如果使用虚拟化，我们建议您留意 4 个重要维度。这些维度或许是任何服务器最重要的特征：<\/p><ul class=\"ibm-bullet-list\"><li>CPU 和内存<\/li><li>磁盘输入/输出 (I/O)<\/li><li>存储<\/li><li>网络<\/li><\/ul><h5 id=\"4.0.1.Table1.Fourdimensionsofvirtualization|outline\">表 1. 虚拟化的 4 个维度<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th>最差的（未管理的）虚拟化特征<\/th><th>最佳的（受管理的）虚拟化特征<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td><strong>CPU<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>芯片组没有 VT 或 V-chip 支持<\/li><li>共享资源池<\/li><li>没有授权的、有保障的或有优先级的调度<\/li><li>其他 VM 的容量未知<\/li><li>vCPU 是物理 CPU 的一小部分<\/li><li>模拟超线程或多线程（非 Nehalem 类）<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>芯片组具有 VT 支持<\/li><li>CPU 关联性允许 VM 具有专用的 vCPU<\/li><li>在与物理 CPU 相等的水平上分配 vCPU<\/li><\/ul><\/td><\/tr><tr><td><strong>内存<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>内存和 CPU 不在同一位置<\/li><li>过度承诺导致过量交换（包括跨其他 VM 交换）<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>设置了关联性<\/li><li>内存和 CPU 在同一位置<\/li><\/ul><\/td><\/tr><tr><td><strong>磁盘 I/O 和存储<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>具有低 IOPS 的单一的本地 SATA 或 IDE 磁盘<\/li><li>本地 RAID，但驱动器槽有限<\/li><li>访问相同存储的通道数量未知<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>光纤通道连接的存储<\/li><li>文件存储<\/li><\/ul><\/td><\/tr><tr><td><strong>网络<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>一个 1G（或更少）网络端口由所有 VM 共享<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>专用网络端口<\/li><li>10G 或更好的网络<\/li><li>链接聚合<\/li><\/ul><\/td><\/tr><\/tbody><\/table><h3 id=\"4.1.CPU|outline\">CPU<\/h3><p>现代 CPU 的设计已考虑了虚拟化。例如，Intel 的 VT 和 AMD 的 V 芯片技术可确保 x86 CPU 最佳地处理虚拟化的负载。其他平台可使用硬件协助的虚拟化，这有望通过对主机 CPU 的直接寻址实现更高效的虚拟化。<\/p><p>在管理最差的虚拟化环境中，实际硬件和 CPU 不支持虚拟化，或者仅通过模拟和较慢的软件层来提供非常有限的支持。在管理最差的环境中，没有投入精力来跟踪其他 VM。事实上，其他 VM 可随意地从其他 VM 轻松地盗走 CPU 周期。零散的 CPU 有时可能会出现，或者是不可避免的，但在经过理想管理的虚拟化环境中，VM 可访问所有物理 CPU。<\/p><h3 id=\"4.2.Memory|outline\">内存<\/h3><p>在管理最差的虚拟化环境中，服务器内存和 CPU 未在同一个总线上。现代硬件利用了非一致内存访问 (NUMA)，因此，处理器访问本地内存的速度比访问位于另一个总线上的远程内存的速度更快。在现代硬件上，与专为高速和可伸缩性而设计的 NUMA 架构背道而驰是毫无意义的。<\/p><p>请提防您的虚拟化软件可能提供的选项和设置，因为它常常很容易与本来高效的 NUMA 架构相抵触。让位于位置 A 的内存引用位于位置 B 的 CPU 似乎很有用，但这种安排会为服务器带来额外的工作，可能导致性能下降。在理想的托管 VM 中，内存和 CPU 位于同一个总线上。<\/p><h3 id=\"4.3.DiskI/Oandstorage|outline\">磁盘 I/O 和存储<\/h3><p>在管理最差的虚拟化环境中，单个本地驱动器支持所有 VM。由于多个服务器共享同一个磁盘，所以实际的 I/O 活动现在发生在磁盘上的多个位置。本地硬盘驱动器可能因为活动量增加而更快地遇到故障。理想情况下，VM 被分配到特定的驱动器上，每个驱动器都有自己的 I/O 和机制。在一些理想环境中，存储可能位于 filer 上，它们非常适合虚拟化的需求并可通过光纤通道进行访问。<\/p><h3 id=\"4.4.Network|outline\">网络<\/h3><p>可能很容易想到一种糟糕的虚拟化网络配置。网卡是根据它们的容量（例如 1 Gb/秒）来度量的。当由 VM 共享时，它们的容量就会被细分（2 个 VM 共享 1 Gb 将得到最大 500 Mb/秒）。管理最差的虚拟化环境中，环境中托管的所有 VM 都共用一个网卡或端口，总吞吐量会由 VM 瓜分。在管理非常理想的虚拟化环境中，每个 VM 都有一个专用的网络端口，或者 VM 共享一个 10 Gb 或更快的网络连接。<em>链路聚合<\/em> 是一种网络技术，其中结合使用了多个网络连接来实现冗余和吞吐量优化。<\/p><h2 id=\"5.Best(managed)virtualizationcharacteristics|outline\">（管理）最佳的虚拟化特征<\/h2><p>对于管理最佳、最理想的虚拟化环境，我们可将前面的要点简单地总结为：<\/p><ul class=\"ibm-bullet-list\"><li>虚拟 CPU 的数量绝不会超过物理 CPU 的数量。<\/li><li>每个 VM 的 CPU 分配与实际的物理 CPU 对应。<\/li><li>虚拟 RAM 量绝不会超过实际 RAM 量。<\/li><li>有充足的存储和网络可供访问。<\/li><\/ul><p>一些人可能会争辩说，此建议违背了虚拟化的宗旨，或者我们有些担忧过度。在理想的世界中，每个 VM 能够按需访问无限多的资源。但是，在实际中，VM 必须共享资源。我们发现，在通过严格管理资源以确保始终有专用的 CPU、内存和其他资源时，Rational 软件在虚拟化服务器上的运行效率是最高的，且操作行为最有效。<\/p><p>如果管理得当，过量使用的资源分配可能是一种可行的虚拟化战略，但这只在实际资源得到紧密监视时才会有效。当确实出现过量使用时，组织必须愿意接受缓慢或无法预测的性能与优化的管理成本之间的折衷方案。<\/p><h2 id=\"6.Itslikemusicalchairs|outline\">就像一种抢椅游戏<\/h2><p>在管理糟糕的虚拟化环境中，虚拟机可任意地共享主机的资源。任何 VM 都可以请求获得比分配给它的更多的内存或 CPU，管理较差的虚拟机管理程序会提供这些资源，对来自其他 VM 的那些请求进行时间分片（time-slicing）。<\/p><p>这实际上就像抢椅游戏。一个 16 处理器、64 GB RAM 服务器可能托管 5 个不同的 4 处理器、16 GB RAM 服务器。当虚拟机 A 需要处理器周期时，它会向主机请求它们。主机将从任何其他 4 个 VM 获取任何未用的处理器时间，或者将其他 VM 的数据写入磁盘以释放资源。<\/p><p>如果 5 个服务器决不会同时以较高容量运行，那么此模型可能会完美地运行。最终用户决不会看到的后端进程可能运行得更慢，存在更多的中断。但是，在应用程序停止或变得缓慢时，最终用户接触的任务关键型应用程序可能会受到过量使用的影响。<\/p><h2 id=\"7.CaseStudyNo.1.TheMysteryMenu,RationalTeamConcertinthreebadlymanagedclouds|outline\">案例分析 1. “The Mystery Menu”，3 个管理较差的云中的 Rational Team Concert<\/h2><p>IBM&#174; Rational&#174; Performance Engineering 团队分析了来自某个云提供商的 3 个 VM 镜像。每个镜像都是不同的，就像我们从一个菜单中选择了小、中和大的分区大小。除了知道每个 VM 所提供的虚拟 CPU 和内存的理论容量之外，我们对 VM 的实际规格知之甚少（存储类型、网络、处理器速度等）。<\/p><p>VM A 有 4 个虚拟 CPU 和 8GB RAM；VM B 有 8 个虚拟 CPU 和 16GB RAM；VM C 有 16 个虚拟 CPU 和 16GB RAM。我们打算向每个镜像提供相同的负载量，查看不同大小的镜像的行为。<\/p><p>我们向 VM A（4 个 vCPU、8GB）提供了一个模拟的多用户负载，CPU 和内存容量使用率很快达到了 100%。性能还可以接受，但我们希望改进它。如果使用物理机器，我们可以立即增加核心数量和 RAM 量，我们过去就是这么做的。<\/p><p>我们向 VM B（8 个 vCPU，16GB）提供了相同的负载，结果令我们大吃一惊：性能显著下降，但与使用的 CPU 和内存成比例。CPU 和内存不再是瓶颈。相反，磁盘 I/O 成为了瓶颈。<\/p><p>当向 VM C（16 个 vCPU，18GB）提供相同的负载时，性能变得更糟糕，而且使用的 CPU 比例进一步降低。瓶颈仍然是磁盘 I/O。（澄清一下，我们将磁盘 I/O 平均分配到每个测试上，以 25% 的增量表示平均值。）<\/p><h5 id=\"N101A7\">图 1. 未管理的云中的 3 个 VM<\/h5><img alt=\"条形图显示了各个 VM 的 CPU、内存和磁盘结果\" src=\"/sunshine_new/images/负624275932/image001.jpg\" width=\"574\" /><p>我们的解释是，这些镜像托管在一个未管理的云上，更大的 VM（B 和 C）事实上从其他 VM 盗取了核心和内存。由于不知道虚拟机管理程序的管理方式，所以我们只能推测过量使用的资源导致了磁盘交换。由于系统将大部分时间用于将其他镜像写入磁盘中，以获取我们的 VM 请求的资源，所以 CPU 未得到充分利用。（在其他 VM 请求周期和 RAM 时，我们的镜像可能也正写入磁盘中。）<\/p><p>图 2 提供了另一种查看相同的数据的方式，显示了未用和已用的内存、未用和已用的 CPU、未用和已用的磁盘的结果。这可以更清楚地解释所发生的事情。<\/p><h5 id=\"N101B5\">图 2. 同样的 3 个 VM 的另一种分析<\/h5><img alt=\"条形图显示了结果\" src=\"/sunshine_new/images/负624275932/image002.jpg\" width=\"576\" /><p>对于图 2，我们描绘了 3 个 VM，以便 CPU 和内存量彼此成比例，我们在图表中使用了 <em>wicket<\/em> 或未填充的条来表示 3 个 VM 未用的 CPU 和内存容量。VM A 使用了分配给它的所有 CPU 和内存，但没有使用太多磁盘。VM B 访问了更多的 CPU 和内存，但无法完全使用它们，因为增多的磁盘活动成为了它的瓶颈。VM C 提供了更多的 CPU，该 VM 仅使用了其中的一少部分，因为像 VM B 一样，VM C 的瓶颈也在磁盘上。<\/p><p>记得管理物理环境的人们可能对这些结果感到惊讶。在大多数具有物理硬件的情况下，增加 CPU 和内存也会提高性能。但是，在管理较差的虚拟化环境中，CPU 和内存是不受限制的，增加 VM 的 CPU 和内存有时可能导致更慢的性能。<\/p><h3 id=\"7.1.Ourconclusions|outline\">我们的结论<\/h3><p>我们的第一个结论是确认，在管理得当的 VM 中，Rational 软件将会正确地执行。案例分析 1 提供了未管理的云中行为不当的应用程序的示例。<\/p><p>第二，我们重申，VM 必须在<em>托管的<\/em> 环境中使用。在此案例分析中，我们没有环境中的虚拟机管理程序或其他 VM 的任何知识。我们相信性能取决于相同环境中其他 VM 的配置和行为，但我们无法确认这一点。<\/p><p>第三，我们告诫不要假设适用于物理硬件的原则也同样适用于 VM 环境。如果拥有过量的 CPU 和内存资源，那么增加 VM 的大小可能会带来提高，但我们实际上会过量使用资源。<\/p><p>最后，我们重申过量使用资源会得到糟糕的 VM，进而导致糟糕的应用程序性能的观点。在此示例中，我们的应用程序是 Rational Team Concert，但我们观察到，无论采用何种虚拟化技术和操作系统，其他 Rational 软件在管理较差的环境中的性能也很差。<\/p><h2 id=\"Sojusthowimportantisaffinity\">案例分析 2.\n                “那么，关联性有多重要？”ClearCase 具有异常负载，并运行在会产生“过量使用”的云中<\/h2><p>我们的下一个示例是在一次会议中实时演示的。我们演示了设置关联性（有时称为<em>授权<\/em> 或<em>专用资源<\/em>）可稳定 IBM Rational 应用程序，而不使用关联性可能导致其他 VM 镜像能够接管资源，并严重减缓您的应用程序性能。<\/p><p>我们使用了一个具有 32 个虚拟 CPU 和 32GB RAM 的 Intel Sandy Bridge 服务器，它托管着两个独立的 IBM&#174; Rational&#174; ClearCase&#174; 部署。每个 ClearCase 部署包含同等的 Red Hat Enterprise Linux (RHEL) 5.5 VM（4 个 vCPU、8GB RAM），以及一个 ClearCase VOB 服务器和托管 Web 视图的 ClearCase CM 服务器。我们使用了 VMware ESX 来托管 VM。部署 A 中托管 ClearCase 的 VM 未使用关联性，而部署 B 中的 ClearCase VM 同时拥有 CPU 和内存关联性。在云外部，在物理硬件上，我们使用了两个 IBM&#174; Rational&#174; Performance Tester 工作台对每个部署进行 100 个用户的负载模拟。<\/p><p>在 ESX 服务器上，我们创建了几个 VM，它们什么都不做，只创造 CPU、内存和磁盘需求。这些 VM 包含执行数学运算和分配所有空闲内存的简单程序，这会得到 100% 的内存使用率和 100% 的 CPU 使用率。我们启动了这些程序，以便以过量使用 ESX 服务器，使其使用率达到 300%。（我们要求这些行为异常的 VM 在虚拟机管理程序上使用 3 倍的物理 CPU 和内存量。）<\/p><p>图 3 和图 4 是从 Rational Performance Tester 获取的。它们展示了部署 A 和部署 B 所执行的 ClearCase 事务的平均响应时间（以毫秒度量）。两种部署的行为一致，直到到达 1,200 秒标记后我们在这些行为异常的 VM 上激活这些程序时。部署 A（其中 ClearCase VM 没有使用关联性运行）的响应时间迅速增加。部署 B（其中 ClearCase VM 使用关联性运行）偶尔会变得缓慢，但是，除了几个峰值外，它一直表现得很稳定。在到达 4000 秒标记时，这些行为异常的镜像停止了，部署 A 返回到正常状态。（请注意，y 轴上的刻度（它显示以毫秒度量的平均事务响应时间）在两个图表中是不同的。）<\/p><h5 id=\"N101F3\">图 3. 没有关联性的部署 A<\/h5><img alt=\"该图表显示了糟糕的 ClearCase 响应时间\" src=\"/sunshine_new/images/负624275932/image003.jpg\" width=\"580\" /><h5 id=\"N101FD\">图 4. 具有 CPU 和内存关联性的部署 B<\/h5><img alt=\"该图表显示了可接受的 ClearCase 响应时间\" src=\"/sunshine_new/images/负624275932/image004.jpg\" width=\"580\" /><p>对比这些测试，没有关联性的部署 A 上的 ClearCase 操作平均花费了 118 秒才完成，而具有关联性的部署 B 平均仅花费了 18 秒。平均而言，具有关联性的部署 B 快 6 到 7 倍。<\/p><h3 id=\"8.1.Ourconclusions|outline\">我们的结论<\/h3><p>案例分析 2 可能是一种极端情况，因为我们创建了一个可能不切实际的行为异常的 VM。但是，我们能够清晰地表明，如果不知道虚拟机管理程序在做什么或者其他 VM 需要请求资源，那么应用程序的性能可能降低。<\/p><p>设置处理器和内存关联性，允许我们关注的 VM 上的应用程序保持一致的性能和行为，甚至在环境中的剩余 VM 执行极端负载时也是如此。<\/p><p>请注意，在没有关联性的部署 A 中，在行为异常的 VM 停止后，性能会恢复正常。如果您的环境中有 VM 允许过量使用资源或不受限制地运行，那么您可能会在自己的 VM 中看到类似的行为。<\/p><p>在此示例中，我们的 Rational 应用程序是 ClearCase，但我们已在管理较差的类似环境中的其他 Rational 软件中看到了类似的糟糕性能，无论采用何种虚拟化技术和操作系统。<\/p><h2 id=\"9.Virtualizationisheretostay,solearntouseitwisely|outline\">虚拟化建立牢固根基，所以请学习如何聪明地使用它<\/h2><p>毋庸置疑，虚拟化已建立牢固根基。越来越多的 IBM Rational 客户开始使用它和依赖它。但是，正如我们所展示的，如果使用不当，虚拟化会给软件的操作带来不利影响。<\/p><p>重要的是理解虚拟化和知道如何管理它。我们希望，我们的案例分析展示了管理较差的虚拟化环境的一些可能的负面影响。在考虑我们的案例分析后，您有可能会识别管理较差的虚拟化环境的症状。在第 2 部分中，我们将探索虚拟化异常的更多症状。我们还会提供故障排除技巧并展示特定于供应商的示例。<\/p><CMA ID: 953009><Site ID: 10><XSLT stylesheet used to transform this file: dw-document-html-7.0.xsl>\r\n\r\n\r\n<\/div>\r\n<\/div>\r\n","createTime":"2014-06-19 00:00:00","deployTime":"2014-06-19 00:00:00","id":0,"intro":"如果您目前正在 IBM Rational 软件上使用虚拟化方法，是否一切都像您预期的一样顺利？三位 IBM 专家将介绍 Rational 视角下的虚拟化，以及虚拟化环境从 Rational 应用程序中获取最优性能的关键要求。他们还将分享两个案例分析的细节和故障排除技巧。","keyword":"","recommend":false,"source":"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-1/index.html","title":"利用虚拟化成就智慧: 第 1 部分：IBM Rational 软件最佳实践","typeId":0,"updateTime":"2014-06-19 00:00:00"}
{"author":"","clickNumber":0,"content":"\r\n<div class=\"ibm-columns\">\r\n<div class=\"ibm-col-1-1\">\r\n\r\n<p>每个人都在谈论虚拟化。根据宣传，虚拟化将引发 IT 革命（众所周知），优化稀缺资源，并节省每个人的钱。服务器虚拟化有望成为 10 年内最重要的发展之一。但是，虚拟化已经存在了很长时间，而且 IBM 已借助 IBM&#174; System z&#174; 和 Power Systems&#8482; 平台成为这一领域的领导者。在过去几年中，System x&#174; 和基于 Intel 的 x86 架构上的虚拟化技术已发展成熟并变得更加普遍。只要使用得当，虚拟化是 IT 工具箱中一个不可或缺的部分。毋庸置疑，虚拟化已有牢固的根基。<\/p><p>但每种技术都存在风险。管理不良的虚拟化可能导致应用程序运行得更慢，这可能导致最终用户厌烦和不满。IBM 为其部署在虚拟化环境中的产品提供了全面支持。或许由于它的普遍性和诱人的承诺，我们看到客户深受管理不良的虚拟化环境所害，导致他们未能获得任何承诺的收益。<\/p><p>这个由两部分组成的文章系列将通过具体示例探讨虚拟化的优缺点。在第 1 部分中，我们将从总体上解释虚拟化，尤其是它与 IBM Rational 软件的关系。我们将讨论管理良好的虚拟化环境的主要要求，展示 IBM&#174; Rational&#174; ClearCase&#174; 和 IBM&#174; Rational Team Concert&#8482; 在配置不良的虚拟化环境中的行为的示例。我们将提供正确管理虚拟化基础架构的建议和技巧，总结我们测试 Rational 软件和为客户提供咨询的经验。<\/p><p>第 2 部分将继续讨论建议和技巧，包括故障排除和特定于供应商的示例。<\/p><div class=\"dw-sidebar ibm-inset\"><h2 id=\"N10094\">虚拟化的简史<\/h2><p>尽管在过去几年，服务器虚拟化以一种富有吸引力的必要技术的形式出现，但它实际上已经存在了很久。上世纪 90 年代，IBM 在 System z 和 System i&#174; 产品线中引入了虚拟机管理程序技术。2000 年，在 System p&#174; 上实现了逻辑分区 (LPAR)。早在 1999 年，就已经在 System x 和基于 Intel 的 x86 硬件上实现了虚拟机。但仅在最近几年，虚拟化才开始在 Microsoft Windows 和 Linux 环境中变得不可或缺。<\/p><\/div><h2 id=\"1.Cloudsintheforecast|outline\">关于云的预测<\/h2><p>虚拟化通常与云技术密不可分。认识二者的关系至关重要。最宽泛地讲，云技术致力于以服务的形式提供服务器功能。虚拟化是一项管理提供该功能的服务器资源的关键技术。<\/p><p>我们还需要区分公有云和私有云。简单地讲，私有云是隔离的，可在一个公司内管理和托管，有时也可以在外部管理和托管。私有云受防火墙、身份验证、VPN\n                等保护。公有云通常没有这么安全，可以高效地由任何人共享和访问。许多流行的公共服务都是 “在云中” 提供的，比如电子邮件、文件和照片存储。公有云模型吸引了一些组织，因为在理论上，组织或个人仅需要为他们所需的内容付费，服务始终可在任何地方享受，而且云提供商处理了大部分 IT 管理任务。<\/p><p>我们发现，一些 IBM Rational 客户对公有云环境的不稳定性和安全问题呲之以鼻。他们喜欢在内部托管、管理更紧密的私有云方法，在这里，他们可以控制服务器资源分配的所有方面，设置特定的服务质量目标，并采用成熟的高可用性和灾难恢复解决方案。<\/p><p>但是，一些客户喜欢基于 IBM 云的解决方案，因为它们是使用软件开发和托管战略最佳实践来设计和管理的。IBM 也在私有云中提供了 Rational 软件。（参见 <a href=\"#resources\">参考资料<\/a> 部分，获取这些选项的更多信息。）<\/p><h2 id=\"2.Basicconcepts|outline\">基本概念<\/h2><p>简单地讲，虚拟化允许将一个较大的服务器（主机或虚拟机管理程序）分割为更小的服务器（Guest、客户端或虚拟机），并共享组合的资源池。众所周知，大多数服务器都不会始终以全容量运行。因此，为什么不共享和组合它们？两个平均剩余 25% 的容量的服务器可变成虚拟机 (VM) 并托管在单个虚拟机管理程序上，这样该虚拟机管理程序就拥有平均大约 50% 的容量。当然，主机操作系统和虚拟机管理程序软件占用了大量的开销，而且还涉及到其他细节。<\/p><p>主机通过软件或模拟来管理客户端的资源。一般而言，虚拟机中没有任何信息能表明它实际上是虚拟的。在大多数情况下，在虚拟机上安装软件的管理员无法确定他们是否在使用虚拟服务器。最新的创新，比如内置于虚拟机管理程序的芯片组中的虚拟化技术，允许更准确地使用优化过的方式来处理硬件资源，比如外围设备驱动程序。<\/p><h2 id=\"3.TheRationalperspectiveonvirtualization|outline\">Rational 视角下的虚拟化<\/h2><p>IBM <a href=\"http://www-01.ibm.com/software/support/virtualization_policy.html\">支持虚拟化<\/a>，因此 IBM Rational 产品受虚拟化的服务器支持。但是，我们坚信虚拟化的基础架构可适当地进行管理和监视。至关重要的是理解您的虚拟化基础架构如何使用<strong>关联性 (affinity)<\/strong> 和<strong>过度承诺 (overcommitment)<\/strong>，而且还要确保您使用关联性和过度承诺的方式可获得 IBM Rational 软件的最佳性能。<\/p><h3 id=\"3.1.Whatisthisthingcalledaffinity?|outline\">何为 “关联性”？<\/h3><p><strong>关联性（Affinity）<\/strong>（也称为<em>entitlement<\/em>、<em>pinning<\/em> 和<em>dedication<\/em>）是将一个虚拟机上的一种或多种资源（例如内存或处理器）专门用于虚拟机管理程序上的相应资源的能力。主机会在虚拟机需要时分配资源。关联性可确保专用于该虚拟机的已请求资源在虚拟机需要时始终可用。<\/p><p>请记住，相同主机上的所有虚拟机都会共享系统资源。<\/p><p><strong>过度承诺<\/strong> 是指虚拟镜像资源分配总量超过硬件的物理资源（一定要计算虚拟机资源）。为了满足虚拟机的峰值需求，虚拟机管理程序可从其他虚拟机获取资源。有时，所有虚拟机的组合需求可能超过虚拟机管理程序的实际资源量。有时，过度承诺可能导致主机上的所有虚拟机都受到影响。<\/p><h2 id=\"4.Virtualization'sfourdimensions|outline\">虚拟化的 4 个维度<\/h2><p>与任何可配置的技术一样，虚拟化也需要进行权衡。从 Rational 产品角度讲，如果使用虚拟化，我们建议您留意 4 个重要维度。这些维度或许是任何服务器最重要的特征：<\/p><ul class=\"ibm-bullet-list\"><li>CPU 和内存<\/li><li>磁盘输入/输出 (I/O)<\/li><li>存储<\/li><li>网络<\/li><\/ul><h5 id=\"4.0.1.Table1.Fourdimensionsofvirtualization|outline\">表 1. 虚拟化的 4 个维度<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th>最差的（未管理的）虚拟化特征<\/th><th>最佳的（受管理的）虚拟化特征<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td><strong>CPU<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>芯片组没有 VT 或 V-chip 支持<\/li><li>共享资源池<\/li><li>没有授权的、有保障的或有优先级的调度<\/li><li>其他 VM 的容量未知<\/li><li>vCPU 是物理 CPU 的一小部分<\/li><li>模拟超线程或多线程（非 Nehalem 类）<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>芯片组具有 VT 支持<\/li><li>CPU 关联性允许 VM 具有专用的 vCPU<\/li><li>在与物理 CPU 相等的水平上分配 vCPU<\/li><\/ul><\/td><\/tr><tr><td><strong>内存<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>内存和 CPU 不在同一位置<\/li><li>过度承诺导致过量交换（包括跨其他 VM 交换）<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>设置了关联性<\/li><li>内存和 CPU 在同一位置<\/li><\/ul><\/td><\/tr><tr><td><strong>磁盘 I/O 和存储<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>具有低 IOPS 的单一的本地 SATA 或 IDE 磁盘<\/li><li>本地 RAID，但驱动器槽有限<\/li><li>访问相同存储的通道数量未知<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>光纤通道连接的存储<\/li><li>文件存储<\/li><\/ul><\/td><\/tr><tr><td><strong>网络<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>一个 1G（或更少）网络端口由所有 VM 共享<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>专用网络端口<\/li><li>10G 或更好的网络<\/li><li>链接聚合<\/li><\/ul><\/td><\/tr><\/tbody><\/table><h3 id=\"4.1.CPU|outline\">CPU<\/h3><p>现代 CPU 的设计已考虑了虚拟化。例如，Intel 的 VT 和 AMD 的 V 芯片技术可确保 x86 CPU 最佳地处理虚拟化的负载。其他平台可使用硬件协助的虚拟化，这有望通过对主机 CPU 的直接寻址实现更高效的虚拟化。<\/p><p>在管理最差的虚拟化环境中，实际硬件和 CPU 不支持虚拟化，或者仅通过模拟和较慢的软件层来提供非常有限的支持。在管理最差的环境中，没有投入精力来跟踪其他 VM。事实上，其他 VM 可随意地从其他 VM 轻松地盗走 CPU 周期。零散的 CPU 有时可能会出现，或者是不可避免的，但在经过理想管理的虚拟化环境中，VM 可访问所有物理 CPU。<\/p><h3 id=\"4.2.Memory|outline\">内存<\/h3><p>在管理最差的虚拟化环境中，服务器内存和 CPU 未在同一个总线上。现代硬件利用了非一致内存访问 (NUMA)，因此，处理器访问本地内存的速度比访问位于另一个总线上的远程内存的速度更快。在现代硬件上，与专为高速和可伸缩性而设计的 NUMA 架构背道而驰是毫无意义的。<\/p><p>请提防您的虚拟化软件可能提供的选项和设置，因为它常常很容易与本来高效的 NUMA 架构相抵触。让位于位置 A 的内存引用位于位置 B 的 CPU 似乎很有用，但这种安排会为服务器带来额外的工作，可能导致性能下降。在理想的托管 VM 中，内存和 CPU 位于同一个总线上。<\/p><h3 id=\"4.3.DiskI/Oandstorage|outline\">磁盘 I/O 和存储<\/h3><p>在管理最差的虚拟化环境中，单个本地驱动器支持所有 VM。由于多个服务器共享同一个磁盘，所以实际的 I/O 活动现在发生在磁盘上的多个位置。本地硬盘驱动器可能因为活动量增加而更快地遇到故障。理想情况下，VM 被分配到特定的驱动器上，每个驱动器都有自己的 I/O 和机制。在一些理想环境中，存储可能位于 filer 上，它们非常适合虚拟化的需求并可通过光纤通道进行访问。<\/p><h3 id=\"4.4.Network|outline\">网络<\/h3><p>可能很容易想到一种糟糕的虚拟化网络配置。网卡是根据它们的容量（例如 1 Gb/秒）来度量的。当由 VM 共享时，它们的容量就会被细分（2 个 VM 共享 1 Gb 将得到最大 500 Mb/秒）。管理最差的虚拟化环境中，环境中托管的所有 VM 都共用一个网卡或端口，总吞吐量会由 VM 瓜分。在管理非常理想的虚拟化环境中，每个 VM 都有一个专用的网络端口，或者 VM 共享一个 10 Gb 或更快的网络连接。<em>链路聚合<\/em> 是一种网络技术，其中结合使用了多个网络连接来实现冗余和吞吐量优化。<\/p><h2 id=\"5.Best(managed)virtualizationcharacteristics|outline\">（管理）最佳的虚拟化特征<\/h2><p>对于管理最佳、最理想的虚拟化环境，我们可将前面的要点简单地总结为：<\/p><ul class=\"ibm-bullet-list\"><li>虚拟 CPU 的数量绝不会超过物理 CPU 的数量。<\/li><li>每个 VM 的 CPU 分配与实际的物理 CPU 对应。<\/li><li>虚拟 RAM 量绝不会超过实际 RAM 量。<\/li><li>有充足的存储和网络可供访问。<\/li><\/ul><p>一些人可能会争辩说，此建议违背了虚拟化的宗旨，或者我们有些担忧过度。在理想的世界中，每个 VM 能够按需访问无限多的资源。但是，在实际中，VM 必须共享资源。我们发现，在通过严格管理资源以确保始终有专用的 CPU、内存和其他资源时，Rational 软件在虚拟化服务器上的运行效率是最高的，且操作行为最有效。<\/p><p>如果管理得当，过量使用的资源分配可能是一种可行的虚拟化战略，但这只在实际资源得到紧密监视时才会有效。当确实出现过量使用时，组织必须愿意接受缓慢或无法预测的性能与优化的管理成本之间的折衷方案。<\/p><h2 id=\"6.Itslikemusicalchairs|outline\">就像一种抢椅游戏<\/h2><p>在管理糟糕的虚拟化环境中，虚拟机可任意地共享主机的资源。任何 VM 都可以请求获得比分配给它的更多的内存或 CPU，管理较差的虚拟机管理程序会提供这些资源，对来自其他 VM 的那些请求进行时间分片（time-slicing）。<\/p><p>这实际上就像抢椅游戏。一个 16 处理器、64 GB RAM 服务器可能托管 5 个不同的 4 处理器、16 GB RAM 服务器。当虚拟机 A 需要处理器周期时，它会向主机请求它们。主机将从任何其他 4 个 VM 获取任何未用的处理器时间，或者将其他 VM 的数据写入磁盘以释放资源。<\/p><p>如果 5 个服务器决不会同时以较高容量运行，那么此模型可能会完美地运行。最终用户决不会看到的后端进程可能运行得更慢，存在更多的中断。但是，在应用程序停止或变得缓慢时，最终用户接触的任务关键型应用程序可能会受到过量使用的影响。<\/p><h2 id=\"7.CaseStudyNo.1.TheMysteryMenu,RationalTeamConcertinthreebadlymanagedclouds|outline\">案例分析 1. “The Mystery Menu”，3 个管理较差的云中的 Rational Team Concert<\/h2><p>IBM&#174; Rational&#174; Performance Engineering 团队分析了来自某个云提供商的 3 个 VM 镜像。每个镜像都是不同的，就像我们从一个菜单中选择了小、中和大的分区大小。除了知道每个 VM 所提供的虚拟 CPU 和内存的理论容量之外，我们对 VM 的实际规格知之甚少（存储类型、网络、处理器速度等）。<\/p><p>VM A 有 4 个虚拟 CPU 和 8GB RAM；VM B 有 8 个虚拟 CPU 和 16GB RAM；VM C 有 16 个虚拟 CPU 和 16GB RAM。我们打算向每个镜像提供相同的负载量，查看不同大小的镜像的行为。<\/p><p>我们向 VM A（4 个 vCPU、8GB）提供了一个模拟的多用户负载，CPU 和内存容量使用率很快达到了 100%。性能还可以接受，但我们希望改进它。如果使用物理机器，我们可以立即增加核心数量和 RAM 量，我们过去就是这么做的。<\/p><p>我们向 VM B（8 个 vCPU，16GB）提供了相同的负载，结果令我们大吃一惊：性能显著下降，但与使用的 CPU 和内存成比例。CPU 和内存不再是瓶颈。相反，磁盘 I/O 成为了瓶颈。<\/p><p>当向 VM C（16 个 vCPU，18GB）提供相同的负载时，性能变得更糟糕，而且使用的 CPU 比例进一步降低。瓶颈仍然是磁盘 I/O。（澄清一下，我们将磁盘 I/O 平均分配到每个测试上，以 25% 的增量表示平均值。）<\/p><h5 id=\"N101A7\">图 1. 未管理的云中的 3 个 VM<\/h5><img alt=\"条形图显示了各个 VM 的 CPU、内存和磁盘结果\" src=\"/sunshine_new/images/负624275932/image001.jpg\" width=\"574\" /><p>我们的解释是，这些镜像托管在一个未管理的云上，更大的 VM（B 和 C）事实上从其他 VM 盗取了核心和内存。由于不知道虚拟机管理程序的管理方式，所以我们只能推测过量使用的资源导致了磁盘交换。由于系统将大部分时间用于将其他镜像写入磁盘中，以获取我们的 VM 请求的资源，所以 CPU 未得到充分利用。（在其他 VM 请求周期和 RAM 时，我们的镜像可能也正写入磁盘中。）<\/p><p>图 2 提供了另一种查看相同的数据的方式，显示了未用和已用的内存、未用和已用的 CPU、未用和已用的磁盘的结果。这可以更清楚地解释所发生的事情。<\/p><h5 id=\"N101B5\">图 2. 同样的 3 个 VM 的另一种分析<\/h5><img alt=\"条形图显示了结果\" src=\"/sunshine_new/images/负624275932/image002.jpg\" width=\"576\" /><p>对于图 2，我们描绘了 3 个 VM，以便 CPU 和内存量彼此成比例，我们在图表中使用了 <em>wicket<\/em> 或未填充的条来表示 3 个 VM 未用的 CPU 和内存容量。VM A 使用了分配给它的所有 CPU 和内存，但没有使用太多磁盘。VM B 访问了更多的 CPU 和内存，但无法完全使用它们，因为增多的磁盘活动成为了它的瓶颈。VM C 提供了更多的 CPU，该 VM 仅使用了其中的一少部分，因为像 VM B 一样，VM C 的瓶颈也在磁盘上。<\/p><p>记得管理物理环境的人们可能对这些结果感到惊讶。在大多数具有物理硬件的情况下，增加 CPU 和内存也会提高性能。但是，在管理较差的虚拟化环境中，CPU 和内存是不受限制的，增加 VM 的 CPU 和内存有时可能导致更慢的性能。<\/p><h3 id=\"7.1.Ourconclusions|outline\">我们的结论<\/h3><p>我们的第一个结论是确认，在管理得当的 VM 中，Rational 软件将会正确地执行。案例分析 1 提供了未管理的云中行为不当的应用程序的示例。<\/p><p>第二，我们重申，VM 必须在<em>托管的<\/em> 环境中使用。在此案例分析中，我们没有环境中的虚拟机管理程序或其他 VM 的任何知识。我们相信性能取决于相同环境中其他 VM 的配置和行为，但我们无法确认这一点。<\/p><p>第三，我们告诫不要假设适用于物理硬件的原则也同样适用于 VM 环境。如果拥有过量的 CPU 和内存资源，那么增加 VM 的大小可能会带来提高，但我们实际上会过量使用资源。<\/p><p>最后，我们重申过量使用资源会得到糟糕的 VM，进而导致糟糕的应用程序性能的观点。在此示例中，我们的应用程序是 Rational Team Concert，但我们观察到，无论采用何种虚拟化技术和操作系统，其他 Rational 软件在管理较差的环境中的性能也很差。<\/p><h2 id=\"Sojusthowimportantisaffinity\">案例分析 2.\n                “那么，关联性有多重要？”ClearCase 具有异常负载，并运行在会产生“过量使用”的云中<\/h2><p>我们的下一个示例是在一次会议中实时演示的。我们演示了设置关联性（有时称为<em>授权<\/em> 或<em>专用资源<\/em>）可稳定 IBM Rational 应用程序，而不使用关联性可能导致其他 VM 镜像能够接管资源，并严重减缓您的应用程序性能。<\/p><p>我们使用了一个具有 32 个虚拟 CPU 和 32GB RAM 的 Intel Sandy Bridge 服务器，它托管着两个独立的 IBM&#174; Rational&#174; ClearCase&#174; 部署。每个 ClearCase 部署包含同等的 Red Hat Enterprise Linux (RHEL) 5.5 VM（4 个 vCPU、8GB RAM），以及一个 ClearCase VOB 服务器和托管 Web 视图的 ClearCase CM 服务器。我们使用了 VMware ESX 来托管 VM。部署 A 中托管 ClearCase 的 VM 未使用关联性，而部署 B 中的 ClearCase VM 同时拥有 CPU 和内存关联性。在云外部，在物理硬件上，我们使用了两个 IBM&#174; Rational&#174; Performance Tester 工作台对每个部署进行 100 个用户的负载模拟。<\/p><p>在 ESX 服务器上，我们创建了几个 VM，它们什么都不做，只创造 CPU、内存和磁盘需求。这些 VM 包含执行数学运算和分配所有空闲内存的简单程序，这会得到 100% 的内存使用率和 100% 的 CPU 使用率。我们启动了这些程序，以便以过量使用 ESX 服务器，使其使用率达到 300%。（我们要求这些行为异常的 VM 在虚拟机管理程序上使用 3 倍的物理 CPU 和内存量。）<\/p><p>图 3 和图 4 是从 Rational Performance Tester 获取的。它们展示了部署 A 和部署 B 所执行的 ClearCase 事务的平均响应时间（以毫秒度量）。两种部署的行为一致，直到到达 1,200 秒标记后我们在这些行为异常的 VM 上激活这些程序时。部署 A（其中 ClearCase VM 没有使用关联性运行）的响应时间迅速增加。部署 B（其中 ClearCase VM 使用关联性运行）偶尔会变得缓慢，但是，除了几个峰值外，它一直表现得很稳定。在到达 4000 秒标记时，这些行为异常的镜像停止了，部署 A 返回到正常状态。（请注意，y 轴上的刻度（它显示以毫秒度量的平均事务响应时间）在两个图表中是不同的。）<\/p><h5 id=\"N101F3\">图 3. 没有关联性的部署 A<\/h5><img alt=\"该图表显示了糟糕的 ClearCase 响应时间\" src=\"/sunshine_new/images/负624275932/image003.jpg\" width=\"580\" /><h5 id=\"N101FD\">图 4. 具有 CPU 和内存关联性的部署 B<\/h5><img alt=\"该图表显示了可接受的 ClearCase 响应时间\" src=\"/sunshine_new/images/负624275932/image004.jpg\" width=\"580\" /><p>对比这些测试，没有关联性的部署 A 上的 ClearCase 操作平均花费了 118 秒才完成，而具有关联性的部署 B 平均仅花费了 18 秒。平均而言，具有关联性的部署 B 快 6 到 7 倍。<\/p><h3 id=\"8.1.Ourconclusions|outline\">我们的结论<\/h3><p>案例分析 2 可能是一种极端情况，因为我们创建了一个可能不切实际的行为异常的 VM。但是，我们能够清晰地表明，如果不知道虚拟机管理程序在做什么或者其他 VM 需要请求资源，那么应用程序的性能可能降低。<\/p><p>设置处理器和内存关联性，允许我们关注的 VM 上的应用程序保持一致的性能和行为，甚至在环境中的剩余 VM 执行极端负载时也是如此。<\/p><p>请注意，在没有关联性的部署 A 中，在行为异常的 VM 停止后，性能会恢复正常。如果您的环境中有 VM 允许过量使用资源或不受限制地运行，那么您可能会在自己的 VM 中看到类似的行为。<\/p><p>在此示例中，我们的 Rational 应用程序是 ClearCase，但我们已在管理较差的类似环境中的其他 Rational 软件中看到了类似的糟糕性能，无论采用何种虚拟化技术和操作系统。<\/p><h2 id=\"9.Virtualizationisheretostay,solearntouseitwisely|outline\">虚拟化建立牢固根基，所以请学习如何聪明地使用它<\/h2><p>毋庸置疑，虚拟化已建立牢固根基。越来越多的 IBM Rational 客户开始使用它和依赖它。但是，正如我们所展示的，如果使用不当，虚拟化会给软件的操作带来不利影响。<\/p><p>重要的是理解虚拟化和知道如何管理它。我们希望，我们的案例分析展示了管理较差的虚拟化环境的一些可能的负面影响。在考虑我们的案例分析后，您有可能会识别管理较差的虚拟化环境的症状。在第 2 部分中，我们将探索虚拟化异常的更多症状。我们还会提供故障排除技巧并展示特定于供应商的示例。<\/p><CMA ID: 953009><Site ID: 10><XSLT stylesheet used to transform this file: dw-document-html-7.0.xsl>\r\n\r\n\r\n<\/div>\r\n<\/div>\r\n","createTime":"2014-06-19 00:00:00","deployTime":"2014-06-19 00:00:00","id":0,"intro":"如果您目前正在 IBM Rational 软件上使用虚拟化方法，是否一切都像您预期的一样顺利？三位 IBM 专家将介绍 Rational 视角下的虚拟化，以及虚拟化环境从 Rational 应用程序中获取最优性能的关键要求。他们还将分享两个案例分析的细节和故障排除技巧。","keyword":"","recommend":false,"source":"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-1/index.html","title":"利用虚拟化成就智慧: 第 1 部分：IBM Rational 软件最佳实践","typeId":0,"updateTime":"2014-06-19 00:00:00"}
{"author":"","clickNumber":0,"content":"\r\n<div class=\"ibm-columns\">\r\n<div class=\"ibm-col-1-1\">\r\n\r\n<p>每个人都在谈论虚拟化。根据宣传，虚拟化将引发 IT 革命（众所周知），优化稀缺资源，并节省每个人的钱。服务器虚拟化有望成为 10 年内最重要的发展之一。但是，虚拟化已经存在了很长时间，而且 IBM 已借助 IBM&#174; System z&#174; 和 Power Systems&#8482; 平台成为这一领域的领导者。在过去几年中，System x&#174; 和基于 Intel 的 x86 架构上的虚拟化技术已发展成熟并变得更加普遍。只要使用得当，虚拟化是 IT 工具箱中一个不可或缺的部分。毋庸置疑，虚拟化已有牢固的根基。<\/p><p>但每种技术都存在风险。管理不良的虚拟化可能导致应用程序运行得更慢，这可能导致最终用户厌烦和不满。IBM 为其部署在虚拟化环境中的产品提供了全面支持。或许由于它的普遍性和诱人的承诺，我们看到客户深受管理不良的虚拟化环境所害，导致他们未能获得任何承诺的收益。<\/p><p>这个由两部分组成的文章系列将通过具体示例探讨虚拟化的优缺点。在第 1 部分中，我们将从总体上解释虚拟化，尤其是它与 IBM Rational 软件的关系。我们将讨论管理良好的虚拟化环境的主要要求，展示 IBM&#174; Rational&#174; ClearCase&#174; 和 IBM&#174; Rational Team Concert&#8482; 在配置不良的虚拟化环境中的行为的示例。我们将提供正确管理虚拟化基础架构的建议和技巧，总结我们测试 Rational 软件和为客户提供咨询的经验。<\/p><p>第 2 部分将继续讨论建议和技巧，包括故障排除和特定于供应商的示例。<\/p><div class=\"dw-sidebar ibm-inset\"><h2 id=\"N10094\">虚拟化的简史<\/h2><p>尽管在过去几年，服务器虚拟化以一种富有吸引力的必要技术的形式出现，但它实际上已经存在了很久。上世纪 90 年代，IBM 在 System z 和 System i&#174; 产品线中引入了虚拟机管理程序技术。2000 年，在 System p&#174; 上实现了逻辑分区 (LPAR)。早在 1999 年，就已经在 System x 和基于 Intel 的 x86 硬件上实现了虚拟机。但仅在最近几年，虚拟化才开始在 Microsoft Windows 和 Linux 环境中变得不可或缺。<\/p><\/div><h2 id=\"1.Cloudsintheforecast|outline\">关于云的预测<\/h2><p>虚拟化通常与云技术密不可分。认识二者的关系至关重要。最宽泛地讲，云技术致力于以服务的形式提供服务器功能。虚拟化是一项管理提供该功能的服务器资源的关键技术。<\/p><p>我们还需要区分公有云和私有云。简单地讲，私有云是隔离的，可在一个公司内管理和托管，有时也可以在外部管理和托管。私有云受防火墙、身份验证、VPN\n                等保护。公有云通常没有这么安全，可以高效地由任何人共享和访问。许多流行的公共服务都是 “在云中” 提供的，比如电子邮件、文件和照片存储。公有云模型吸引了一些组织，因为在理论上，组织或个人仅需要为他们所需的内容付费，服务始终可在任何地方享受，而且云提供商处理了大部分 IT 管理任务。<\/p><p>我们发现，一些 IBM Rational 客户对公有云环境的不稳定性和安全问题呲之以鼻。他们喜欢在内部托管、管理更紧密的私有云方法，在这里，他们可以控制服务器资源分配的所有方面，设置特定的服务质量目标，并采用成熟的高可用性和灾难恢复解决方案。<\/p><p>但是，一些客户喜欢基于 IBM 云的解决方案，因为它们是使用软件开发和托管战略最佳实践来设计和管理的。IBM 也在私有云中提供了 Rational 软件。（参见 <a href=\"#resources\">参考资料<\/a> 部分，获取这些选项的更多信息。）<\/p><h2 id=\"2.Basicconcepts|outline\">基本概念<\/h2><p>简单地讲，虚拟化允许将一个较大的服务器（主机或虚拟机管理程序）分割为更小的服务器（Guest、客户端或虚拟机），并共享组合的资源池。众所周知，大多数服务器都不会始终以全容量运行。因此，为什么不共享和组合它们？两个平均剩余 25% 的容量的服务器可变成虚拟机 (VM) 并托管在单个虚拟机管理程序上，这样该虚拟机管理程序就拥有平均大约 50% 的容量。当然，主机操作系统和虚拟机管理程序软件占用了大量的开销，而且还涉及到其他细节。<\/p><p>主机通过软件或模拟来管理客户端的资源。一般而言，虚拟机中没有任何信息能表明它实际上是虚拟的。在大多数情况下，在虚拟机上安装软件的管理员无法确定他们是否在使用虚拟服务器。最新的创新，比如内置于虚拟机管理程序的芯片组中的虚拟化技术，允许更准确地使用优化过的方式来处理硬件资源，比如外围设备驱动程序。<\/p><h2 id=\"3.TheRationalperspectiveonvirtualization|outline\">Rational 视角下的虚拟化<\/h2><p>IBM <a href=\"http://www-01.ibm.com/software/support/virtualization_policy.html\">支持虚拟化<\/a>，因此 IBM Rational 产品受虚拟化的服务器支持。但是，我们坚信虚拟化的基础架构可适当地进行管理和监视。至关重要的是理解您的虚拟化基础架构如何使用<strong>关联性 (affinity)<\/strong> 和<strong>过度承诺 (overcommitment)<\/strong>，而且还要确保您使用关联性和过度承诺的方式可获得 IBM Rational 软件的最佳性能。<\/p><h3 id=\"3.1.Whatisthisthingcalledaffinity?|outline\">何为 “关联性”？<\/h3><p><strong>关联性（Affinity）<\/strong>（也称为<em>entitlement<\/em>、<em>pinning<\/em> 和<em>dedication<\/em>）是将一个虚拟机上的一种或多种资源（例如内存或处理器）专门用于虚拟机管理程序上的相应资源的能力。主机会在虚拟机需要时分配资源。关联性可确保专用于该虚拟机的已请求资源在虚拟机需要时始终可用。<\/p><p>请记住，相同主机上的所有虚拟机都会共享系统资源。<\/p><p><strong>过度承诺<\/strong> 是指虚拟镜像资源分配总量超过硬件的物理资源（一定要计算虚拟机资源）。为了满足虚拟机的峰值需求，虚拟机管理程序可从其他虚拟机获取资源。有时，所有虚拟机的组合需求可能超过虚拟机管理程序的实际资源量。有时，过度承诺可能导致主机上的所有虚拟机都受到影响。<\/p><h2 id=\"4.Virtualization'sfourdimensions|outline\">虚拟化的 4 个维度<\/h2><p>与任何可配置的技术一样，虚拟化也需要进行权衡。从 Rational 产品角度讲，如果使用虚拟化，我们建议您留意 4 个重要维度。这些维度或许是任何服务器最重要的特征：<\/p><ul class=\"ibm-bullet-list\"><li>CPU 和内存<\/li><li>磁盘输入/输出 (I/O)<\/li><li>存储<\/li><li>网络<\/li><\/ul><h5 id=\"4.0.1.Table1.Fourdimensionsofvirtualization|outline\">表 1. 虚拟化的 4 个维度<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th>最差的（未管理的）虚拟化特征<\/th><th>最佳的（受管理的）虚拟化特征<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td><strong>CPU<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>芯片组没有 VT 或 V-chip 支持<\/li><li>共享资源池<\/li><li>没有授权的、有保障的或有优先级的调度<\/li><li>其他 VM 的容量未知<\/li><li>vCPU 是物理 CPU 的一小部分<\/li><li>模拟超线程或多线程（非 Nehalem 类）<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>芯片组具有 VT 支持<\/li><li>CPU 关联性允许 VM 具有专用的 vCPU<\/li><li>在与物理 CPU 相等的水平上分配 vCPU<\/li><\/ul><\/td><\/tr><tr><td><strong>内存<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>内存和 CPU 不在同一位置<\/li><li>过度承诺导致过量交换（包括跨其他 VM 交换）<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>设置了关联性<\/li><li>内存和 CPU 在同一位置<\/li><\/ul><\/td><\/tr><tr><td><strong>磁盘 I/O 和存储<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>具有低 IOPS 的单一的本地 SATA 或 IDE 磁盘<\/li><li>本地 RAID，但驱动器槽有限<\/li><li>访问相同存储的通道数量未知<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>光纤通道连接的存储<\/li><li>文件存储<\/li><\/ul><\/td><\/tr><tr><td><strong>网络<\/strong><\/td><td><ul class=\"ibm-bullet-list\"><li>一个 1G（或更少）网络端口由所有 VM 共享<\/li><\/ul><\/td><td><ul class=\"ibm-bullet-list\"><li>专用网络端口<\/li><li>10G 或更好的网络<\/li><li>链接聚合<\/li><\/ul><\/td><\/tr><\/tbody><\/table><h3 id=\"4.1.CPU|outline\">CPU<\/h3><p>现代 CPU 的设计已考虑了虚拟化。例如，Intel 的 VT 和 AMD 的 V 芯片技术可确保 x86 CPU 最佳地处理虚拟化的负载。其他平台可使用硬件协助的虚拟化，这有望通过对主机 CPU 的直接寻址实现更高效的虚拟化。<\/p><p>在管理最差的虚拟化环境中，实际硬件和 CPU 不支持虚拟化，或者仅通过模拟和较慢的软件层来提供非常有限的支持。在管理最差的环境中，没有投入精力来跟踪其他 VM。事实上，其他 VM 可随意地从其他 VM 轻松地盗走 CPU 周期。零散的 CPU 有时可能会出现，或者是不可避免的，但在经过理想管理的虚拟化环境中，VM 可访问所有物理 CPU。<\/p><h3 id=\"4.2.Memory|outline\">内存<\/h3><p>在管理最差的虚拟化环境中，服务器内存和 CPU 未在同一个总线上。现代硬件利用了非一致内存访问 (NUMA)，因此，处理器访问本地内存的速度比访问位于另一个总线上的远程内存的速度更快。在现代硬件上，与专为高速和可伸缩性而设计的 NUMA 架构背道而驰是毫无意义的。<\/p><p>请提防您的虚拟化软件可能提供的选项和设置，因为它常常很容易与本来高效的 NUMA 架构相抵触。让位于位置 A 的内存引用位于位置 B 的 CPU 似乎很有用，但这种安排会为服务器带来额外的工作，可能导致性能下降。在理想的托管 VM 中，内存和 CPU 位于同一个总线上。<\/p><h3 id=\"4.3.DiskI/Oandstorage|outline\">磁盘 I/O 和存储<\/h3><p>在管理最差的虚拟化环境中，单个本地驱动器支持所有 VM。由于多个服务器共享同一个磁盘，所以实际的 I/O 活动现在发生在磁盘上的多个位置。本地硬盘驱动器可能因为活动量增加而更快地遇到故障。理想情况下，VM 被分配到特定的驱动器上，每个驱动器都有自己的 I/O 和机制。在一些理想环境中，存储可能位于 filer 上，它们非常适合虚拟化的需求并可通过光纤通道进行访问。<\/p><h3 id=\"4.4.Network|outline\">网络<\/h3><p>可能很容易想到一种糟糕的虚拟化网络配置。网卡是根据它们的容量（例如 1 Gb/秒）来度量的。当由 VM 共享时，它们的容量就会被细分（2 个 VM 共享 1 Gb 将得到最大 500 Mb/秒）。管理最差的虚拟化环境中，环境中托管的所有 VM 都共用一个网卡或端口，总吞吐量会由 VM 瓜分。在管理非常理想的虚拟化环境中，每个 VM 都有一个专用的网络端口，或者 VM 共享一个 10 Gb 或更快的网络连接。<em>链路聚合<\/em> 是一种网络技术，其中结合使用了多个网络连接来实现冗余和吞吐量优化。<\/p><h2 id=\"5.Best(managed)virtualizationcharacteristics|outline\">（管理）最佳的虚拟化特征<\/h2><p>对于管理最佳、最理想的虚拟化环境，我们可将前面的要点简单地总结为：<\/p><ul class=\"ibm-bullet-list\"><li>虚拟 CPU 的数量绝不会超过物理 CPU 的数量。<\/li><li>每个 VM 的 CPU 分配与实际的物理 CPU 对应。<\/li><li>虚拟 RAM 量绝不会超过实际 RAM 量。<\/li><li>有充足的存储和网络可供访问。<\/li><\/ul><p>一些人可能会争辩说，此建议违背了虚拟化的宗旨，或者我们有些担忧过度。在理想的世界中，每个 VM 能够按需访问无限多的资源。但是，在实际中，VM 必须共享资源。我们发现，在通过严格管理资源以确保始终有专用的 CPU、内存和其他资源时，Rational 软件在虚拟化服务器上的运行效率是最高的，且操作行为最有效。<\/p><p>如果管理得当，过量使用的资源分配可能是一种可行的虚拟化战略，但这只在实际资源得到紧密监视时才会有效。当确实出现过量使用时，组织必须愿意接受缓慢或无法预测的性能与优化的管理成本之间的折衷方案。<\/p><h2 id=\"6.Itslikemusicalchairs|outline\">就像一种抢椅游戏<\/h2><p>在管理糟糕的虚拟化环境中，虚拟机可任意地共享主机的资源。任何 VM 都可以请求获得比分配给它的更多的内存或 CPU，管理较差的虚拟机管理程序会提供这些资源，对来自其他 VM 的那些请求进行时间分片（time-slicing）。<\/p><p>这实际上就像抢椅游戏。一个 16 处理器、64 GB RAM 服务器可能托管 5 个不同的 4 处理器、16 GB RAM 服务器。当虚拟机 A 需要处理器周期时，它会向主机请求它们。主机将从任何其他 4 个 VM 获取任何未用的处理器时间，或者将其他 VM 的数据写入磁盘以释放资源。<\/p><p>如果 5 个服务器决不会同时以较高容量运行，那么此模型可能会完美地运行。最终用户决不会看到的后端进程可能运行得更慢，存在更多的中断。但是，在应用程序停止或变得缓慢时，最终用户接触的任务关键型应用程序可能会受到过量使用的影响。<\/p><h2 id=\"7.CaseStudyNo.1.TheMysteryMenu,RationalTeamConcertinthreebadlymanagedclouds|outline\">案例分析 1. “The Mystery Menu”，3 个管理较差的云中的 Rational Team Concert<\/h2><p>IBM&#174; Rational&#174; Performance Engineering 团队分析了来自某个云提供商的 3 个 VM 镜像。每个镜像都是不同的，就像我们从一个菜单中选择了小、中和大的分区大小。除了知道每个 VM 所提供的虚拟 CPU 和内存的理论容量之外，我们对 VM 的实际规格知之甚少（存储类型、网络、处理器速度等）。<\/p><p>VM A 有 4 个虚拟 CPU 和 8GB RAM；VM B 有 8 个虚拟 CPU 和 16GB RAM；VM C 有 16 个虚拟 CPU 和 16GB RAM。我们打算向每个镜像提供相同的负载量，查看不同大小的镜像的行为。<\/p><p>我们向 VM A（4 个 vCPU、8GB）提供了一个模拟的多用户负载，CPU 和内存容量使用率很快达到了 100%。性能还可以接受，但我们希望改进它。如果使用物理机器，我们可以立即增加核心数量和 RAM 量，我们过去就是这么做的。<\/p><p>我们向 VM B（8 个 vCPU，16GB）提供了相同的负载，结果令我们大吃一惊：性能显著下降，但与使用的 CPU 和内存成比例。CPU 和内存不再是瓶颈。相反，磁盘 I/O 成为了瓶颈。<\/p><p>当向 VM C（16 个 vCPU，18GB）提供相同的负载时，性能变得更糟糕，而且使用的 CPU 比例进一步降低。瓶颈仍然是磁盘 I/O。（澄清一下，我们将磁盘 I/O 平均分配到每个测试上，以 25% 的增量表示平均值。）<\/p><h5 id=\"N101A7\">图 1. 未管理的云中的 3 个 VM<\/h5><img alt=\"条形图显示了各个 VM 的 CPU、内存和磁盘结果\" src=\"/sunshine_new/images/负624275932/image001.jpg\" width=\"574\" /><p>我们的解释是，这些镜像托管在一个未管理的云上，更大的 VM（B 和 C）事实上从其他 VM 盗取了核心和内存。由于不知道虚拟机管理程序的管理方式，所以我们只能推测过量使用的资源导致了磁盘交换。由于系统将大部分时间用于将其他镜像写入磁盘中，以获取我们的 VM 请求的资源，所以 CPU 未得到充分利用。（在其他 VM 请求周期和 RAM 时，我们的镜像可能也正写入磁盘中。）<\/p><p>图 2 提供了另一种查看相同的数据的方式，显示了未用和已用的内存、未用和已用的 CPU、未用和已用的磁盘的结果。这可以更清楚地解释所发生的事情。<\/p><h5 id=\"N101B5\">图 2. 同样的 3 个 VM 的另一种分析<\/h5><img alt=\"条形图显示了结果\" src=\"/sunshine_new/images/负624275932/image002.jpg\" width=\"576\" /><p>对于图 2，我们描绘了 3 个 VM，以便 CPU 和内存量彼此成比例，我们在图表中使用了 <em>wicket<\/em> 或未填充的条来表示 3 个 VM 未用的 CPU 和内存容量。VM A 使用了分配给它的所有 CPU 和内存，但没有使用太多磁盘。VM B 访问了更多的 CPU 和内存，但无法完全使用它们，因为增多的磁盘活动成为了它的瓶颈。VM C 提供了更多的 CPU，该 VM 仅使用了其中的一少部分，因为像 VM B 一样，VM C 的瓶颈也在磁盘上。<\/p><p>记得管理物理环境的人们可能对这些结果感到惊讶。在大多数具有物理硬件的情况下，增加 CPU 和内存也会提高性能。但是，在管理较差的虚拟化环境中，CPU 和内存是不受限制的，增加 VM 的 CPU 和内存有时可能导致更慢的性能。<\/p><h3 id=\"7.1.Ourconclusions|outline\">我们的结论<\/h3><p>我们的第一个结论是确认，在管理得当的 VM 中，Rational 软件将会正确地执行。案例分析 1 提供了未管理的云中行为不当的应用程序的示例。<\/p><p>第二，我们重申，VM 必须在<em>托管的<\/em> 环境中使用。在此案例分析中，我们没有环境中的虚拟机管理程序或其他 VM 的任何知识。我们相信性能取决于相同环境中其他 VM 的配置和行为，但我们无法确认这一点。<\/p><p>第三，我们告诫不要假设适用于物理硬件的原则也同样适用于 VM 环境。如果拥有过量的 CPU 和内存资源，那么增加 VM 的大小可能会带来提高，但我们实际上会过量使用资源。<\/p><p>最后，我们重申过量使用资源会得到糟糕的 VM，进而导致糟糕的应用程序性能的观点。在此示例中，我们的应用程序是 Rational Team Concert，但我们观察到，无论采用何种虚拟化技术和操作系统，其他 Rational 软件在管理较差的环境中的性能也很差。<\/p><h2 id=\"Sojusthowimportantisaffinity\">案例分析 2.\n                “那么，关联性有多重要？”ClearCase 具有异常负载，并运行在会产生“过量使用”的云中<\/h2><p>我们的下一个示例是在一次会议中实时演示的。我们演示了设置关联性（有时称为<em>授权<\/em> 或<em>专用资源<\/em>）可稳定 IBM Rational 应用程序，而不使用关联性可能导致其他 VM 镜像能够接管资源，并严重减缓您的应用程序性能。<\/p><p>我们使用了一个具有 32 个虚拟 CPU 和 32GB RAM 的 Intel Sandy Bridge 服务器，它托管着两个独立的 IBM&#174; Rational&#174; ClearCase&#174; 部署。每个 ClearCase 部署包含同等的 Red Hat Enterprise Linux (RHEL) 5.5 VM（4 个 vCPU、8GB RAM），以及一个 ClearCase VOB 服务器和托管 Web 视图的 ClearCase CM 服务器。我们使用了 VMware ESX 来托管 VM。部署 A 中托管 ClearCase 的 VM 未使用关联性，而部署 B 中的 ClearCase VM 同时拥有 CPU 和内存关联性。在云外部，在物理硬件上，我们使用了两个 IBM&#174; Rational&#174; Performance Tester 工作台对每个部署进行 100 个用户的负载模拟。<\/p><p>在 ESX 服务器上，我们创建了几个 VM，它们什么都不做，只创造 CPU、内存和磁盘需求。这些 VM 包含执行数学运算和分配所有空闲内存的简单程序，这会得到 100% 的内存使用率和 100% 的 CPU 使用率。我们启动了这些程序，以便以过量使用 ESX 服务器，使其使用率达到 300%。（我们要求这些行为异常的 VM 在虚拟机管理程序上使用 3 倍的物理 CPU 和内存量。）<\/p><p>图 3 和图 4 是从 Rational Performance Tester 获取的。它们展示了部署 A 和部署 B 所执行的 ClearCase 事务的平均响应时间（以毫秒度量）。两种部署的行为一致，直到到达 1,200 秒标记后我们在这些行为异常的 VM 上激活这些程序时。部署 A（其中 ClearCase VM 没有使用关联性运行）的响应时间迅速增加。部署 B（其中 ClearCase VM 使用关联性运行）偶尔会变得缓慢，但是，除了几个峰值外，它一直表现得很稳定。在到达 4000 秒标记时，这些行为异常的镜像停止了，部署 A 返回到正常状态。（请注意，y 轴上的刻度（它显示以毫秒度量的平均事务响应时间）在两个图表中是不同的。）<\/p><h5 id=\"N101F3\">图 3. 没有关联性的部署 A<\/h5><img alt=\"该图表显示了糟糕的 ClearCase 响应时间\" src=\"/sunshine_new/images/负624275932/image003.jpg\" width=\"580\" /><h5 id=\"N101FD\">图 4. 具有 CPU 和内存关联性的部署 B<\/h5><img alt=\"该图表显示了可接受的 ClearCase 响应时间\" src=\"/sunshine_new/images/负624275932/image004.jpg\" width=\"580\" /><p>对比这些测试，没有关联性的部署 A 上的 ClearCase 操作平均花费了 118 秒才完成，而具有关联性的部署 B 平均仅花费了 18 秒。平均而言，具有关联性的部署 B 快 6 到 7 倍。<\/p><h3 id=\"8.1.Ourconclusions|outline\">我们的结论<\/h3><p>案例分析 2 可能是一种极端情况，因为我们创建了一个可能不切实际的行为异常的 VM。但是，我们能够清晰地表明，如果不知道虚拟机管理程序在做什么或者其他 VM 需要请求资源，那么应用程序的性能可能降低。<\/p><p>设置处理器和内存关联性，允许我们关注的 VM 上的应用程序保持一致的性能和行为，甚至在环境中的剩余 VM 执行极端负载时也是如此。<\/p><p>请注意，在没有关联性的部署 A 中，在行为异常的 VM 停止后，性能会恢复正常。如果您的环境中有 VM 允许过量使用资源或不受限制地运行，那么您可能会在自己的 VM 中看到类似的行为。<\/p><p>在此示例中，我们的 Rational 应用程序是 ClearCase，但我们已在管理较差的类似环境中的其他 Rational 软件中看到了类似的糟糕性能，无论采用何种虚拟化技术和操作系统。<\/p><h2 id=\"9.Virtualizationisheretostay,solearntouseitwisely|outline\">虚拟化建立牢固根基，所以请学习如何聪明地使用它<\/h2><p>毋庸置疑，虚拟化已建立牢固根基。越来越多的 IBM Rational 客户开始使用它和依赖它。但是，正如我们所展示的，如果使用不当，虚拟化会给软件的操作带来不利影响。<\/p><p>重要的是理解虚拟化和知道如何管理它。我们希望，我们的案例分析展示了管理较差的虚拟化环境的一些可能的负面影响。在考虑我们的案例分析后，您有可能会识别管理较差的虚拟化环境的症状。在第 2 部分中，我们将探索虚拟化异常的更多症状。我们还会提供故障排除技巧并展示特定于供应商的示例。<\/p><CMA ID: 953009><Site ID: 10><XSLT stylesheet used to transform this file: dw-document-html-7.0.xsl>\r\n\r\n\r\n<\/div>\r\n<\/div>\r\n","createTime":"2014-06-19 00:00:00","deployTime":"2014-06-19 00:00:00","id":0,"intro":"如果您目前正在 IBM Rational 软件上使用虚拟化方法，是否一切都像您预期的一样顺利？三位 IBM 专家将介绍 Rational 视角下的虚拟化，以及虚拟化环境从 Rational 应用程序中获取最优性能的关键要求。他们还将分享两个案例分析的细节和故障排除技巧。","keyword":"","recommend":false,"source":"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-1/index.html","title":"利用虚拟化成就智慧: 第 1 部分：IBM Rational 软件最佳实践","typeId":0,"updateTime":"2014-06-19 00:00:00"}
{"author":"","clickNumber":0,"content":"\r\n<div class=\"ibm-columns\">\r\n<div class=\"ibm-col-1-1\">\r\n\r\n<div class=\"dw-sidebar ibm-inset\"><h2 id=\"N10073\">虚拟化的四个维度<\/h2><p>CPU<br />内存<br />磁盘输入/输出（I/O）及存储<br />网络<\/p><\/div><p>这个由两部分组成的系列文章将通过具体示例探讨虚拟化的优缺点。在<a href=\"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-1/\">第 1 部分<\/a>中，我们将从总体上解释虚拟化，尤其是它与 IBM Rational 软件的关系。我们将覆盖虚拟化的四个维度，CPU、内存、磁盘输入/输出（I/O）及存储、网络等应如何通过关联性（专用资源）被恰当地管理而不会过度承诺。我们所给出的例子展示了被恰当管理的虚拟化是如何彻底影响  IBM&#174; Rational&#174; 产品。尤其是我们所展示的两个案例分析，其中的 IBM&#174; Rational Team Concert&#8482; 及 IBM&#174; Rational&#174; ClearCase&#174; 托管在没有关联性配置的虚拟机中，虚拟环境配置欠佳，从而使之性能糟糕。<\/p><p>在第 2 部分中，我们将更加深入探究针对过度承诺的折中考虑。基于我们在 Rational 产品和曾服务客户身上测试得来的经验，我们将提供建议和技巧，故障排除和特定于供应商的示例来帮助您更好地管理您的虚拟化基础设施。所有提及的故障排除场景和建议都来自 <a href=\"https://jazz.net/wiki/bin/view/Deployment/VirtualizationTroubleshooting\">jazz.net Deployment wiki<\/a>。<\/p><h2 id=\"casestudyno3\">案例分析 3. 结合 ClearCase\n                探索过度承诺（overcommitment）<\/h2><p>案例分析 2 演示了当托管在没有专用资源的虚拟机（VM）上时，IBM Rational ClearCase 是如何糟糕。我们建议要为 IBM Rational 产品配置关联性和专用资源，来避免可能存在的过度承诺。然而，我们也认识到受管理的过度承诺对于虚拟化而言仍然具有显著的价值。案例分析 3 着眼于不同程度的过度承诺。<\/p><p>在我们其中之一的测试中，我们考察了一台拥有 4 个八核 CPU 及 64 GB内存的 Intel Westmere-EX 服务器。这台服务器启用了超线程，对于虚拟机管理程序（hypervisor）而言，这台拥有 32 个核心的服务器就如同拥有 64 个逻辑处理器（64 vCPU）。ClearCase CM 服务器安装在其中一个拥有 4 vCPU 和 8 GB RAM 的 VM 上，但没有专用资源或关联性。<\/p><p>在同一个虚拟机管理程序上我们还创建了 96 个拥有 4 vCPU 和 4 GB RAM 的 VM（64-位 RHEL 5.5）。这些 96 个镜像被用于产生背景负载。这 96 个镜像被组织成六组 16 VM 群组。每一个 16-VM 群组包括 64 vCPU 和 64 GB RAM，这与 Westmere-EX 自身的硬件维度是相符合的。因此每一个 16-VM 群组都 100%　体现了 Westmere-EX 服务器的硬件配给。<\/p><p>为了捕获基线平均响应时间数据（如表 1 a 行所示），我们仿真了 100 个用户的 UCM 负载并传递给 ClearCase CM 服务器。所有六组\n                VM 则处于挂起状态。<\/p><p>在下一个测试（表 1 中 b 行到 g 行），我们使用了六组 16 VM 的群组来创建背景负载。每一个 VM 都托管一个本机程序，运行多线程的平方根数学计算并分配了内存。这一“贪婪”程序确保每一个 VM 客户端将会 100% 消耗为它分配的处理器和内存。每一个测试以 16 个 VM 或 100% 相应的 Westmere-EX 服务器物理硬件为单位增加背景负载。<\/p><p>行 b 显示了 100 个用户 CC CM 服务器测试的平均响应时间数据，以及相应的 100% 的 Westmere-EX 负载（一组 16 VM 都运行“贪婪”程序）。行 c 到行 g 显示了 100 用户 CC CM 服务器测试随着逐步增加每一组 16 VM 的平均响应时间数据（每一步都逐步增加 100% 相应的 Westmere-EX 服务器负载）。<\/p><p>行 g 显示了在所有 96 个 VM 都在运行“贪婪”程序，即 600% 物理 Westmere-EX 服务器容量的情况下，我们的 100 个用户 CC CM 服务器测试的平均响应时间。响应时间非常糟糕。我们过度承诺的服务器无法在合理的响应时间内为 100 个用户 CC 负载提供服务。<\/p><p>让我们的服务器保证合理的性能的唯一办法是运行在一个具有专用资源的 VM 上。行 h 显示了与行 g 相同的测试，但 CC CM 服务器具有关联性和专用资源。在 600% 的负载下，CC CM 服务器以可接受的性能进行了响应。<\/p><h5 id=\"Table1\">表 1：使用 ClearCase 来展示关联性效果的性能测试<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"9 column table with heading row and center-aligned content\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th>a<br />物理机器<\/th><th>b<br />100% 无关联性的负载<\/th><th>c<br />200% 无关联性的负载<\/th><th>d<br />300% 无关联性的负载<\/th><th>e<br />400% 无关联性的负载<\/th><th>f<br />500% 无关联性的负载<\/th><th>g<br />600% 无关联性的负载<\/th><th>h<br />600% 有关联性的负载<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td><strong>产生流<\/strong><\/td><td><strong>1.03<\/strong><\/td><td> 1.57 <\/td><td><strong>1.87<\/strong><\/td><td> 3.48 <\/td><td> 29.81 <\/td><td> 39.76 <\/td><td> 153.29 <\/td><td><strong>1.88<\/strong><\/td><\/tr><tr><td><strong>产生活动<\/strong><\/td><td><strong>0.33<\/strong><\/td><td> 0.50 <\/td><td><strong>0.55<\/strong><\/td><td> 1.64 <\/td><td> 24.84 <\/td><td> 44.35 <\/td><td> 176.21 <\/td><td><strong>0.61<\/strong><\/td><\/tr><tr><td><strong>集活动<\/strong><\/td><td><strong>0.59<\/strong><\/td><td> 0.92 <\/td><td><strong>1.04<\/strong><\/td><td> 3.59 <\/td><td> 68.55 <\/td><td> 69.45 <\/td><td> 159.14 <\/td><td><strong>0.99<\/strong><\/td><\/tr><tr><td><strong>产生目录<\/strong><\/td><td><strong>1.98<\/strong><\/td><td> 2.78 <\/td><td><strong>3.04<\/strong><\/td><td> 4.93 <\/td><td> 64.72 <\/td><td> 70.43 <\/td><td> 161.33 <\/td><td><strong>3.35<\/strong><\/td><\/tr><tr><td><strong>检出目录<\/strong><\/td><td><strong>0.72<\/strong><\/td><td> 0.91 <\/td><td><strong>0.97<\/strong><\/td><td> 2.08 <\/td><td> 30.82 <\/td><td> 38.17 <\/td><td> 125.30 <\/td><td><strong>1.12<\/strong><\/td><\/tr><tr><td><strong>检入目录<\/strong><\/td><td><strong>0.61<\/strong><\/td><td> 0.78 <\/td><td><strong>0.82<\/strong><\/td><td> 1.35 <\/td><td> 11.86 <\/td><td> 13.73 <\/td><td> 68.03 <\/td><td><strong>0.91<\/strong><\/td><\/tr><tr><td><strong>产生文件<\/strong><\/td><td><strong>1.40<\/strong><\/td><td> 1.78 <\/td><td><strong>1.93<\/strong><\/td><td> 3.23 <\/td><td> 33.10 <\/td><td> 37.54 <\/td><td> 95.58 <\/td><td><strong>2.28<\/strong><\/td><\/tr><tr><td><strong>检出文件<\/strong><\/td><td><strong>0.91<\/strong><\/td><td> 1.25 <\/td><td><strong>1.45<\/strong><\/td><td> 1.51 <\/td><td> 3.81 <\/td><td> 5.42 <\/td><td> 68.12 <\/td><td><strong>1.47<\/strong><\/td><\/tr><\/tbody><\/table><p>这个例子展示了多个情况。没有关联性，产品的性能会大幅度降低到不可用的程度。更进一步，仅仅拥有 CC CM 服务器访问权限的 ClearCase 管理员无法理解甚至无法猜测究竟发生了什么情况。这个背景负载也许过于极端，但非常清晰地演示了过度承诺的影响。<\/p><p>不过，虚拟化并不是一个无助的命题。比较表 1 中的 c 和 h 行，这两行显示了 CC CM 服务器在没有关联性而虚拟机管理程序承担 200% 负载时，以及 CC CM 服务器有关联性而虚拟机管理程序承担 200% 负载时的情形。两种情形相似的响应时间足以表明，如果不可能有专用资源时虚拟机管理程序的能力无法承担超过 200% 负载，而对于资源有关联性的配置则可以提供可接受的响应时间。这个事实表明，如果管理得当的话，过度承诺可以成为一个切实可行的选择。<\/p><h2 id=\"casestudyno4\">案例分析 4. 过度承诺或低于承诺：性能 vs. 能力<\/h2><p>案例分析 4 比较了两个不同 VM 配置在同一台 ESX 服务器，即一台 32 vCPU 及 32 GB RAM 的 Intel SandyBridge 服务器（E5-2680 @\n                2.70GHz）上时 ClearCase 的响应时间。配置 A 使用了 100% 的 VMware ESX 的能力，而配置 B 则使用了 150%。<\/p><p>在配置 A 中，ESX 服务器托管 VOB 服务器，一个 ClearCase Remote Client（CCRC）服务器以及两个 VM 运行案例 3 中描述的“贪婪”程序。每一个 ESX 服务器上的 VM 运行 RHEL 5.6，并分配了 8 vCPU 和 8 GB RAM。配置 A 拥有  100% 专用的 ESX 硬件资源。<\/p><p>配置 B 使用配置 A 相同的四个 VM；不过，额外的两个 VM 被增加到 ESX 服务器上。这两个额外的 VM 具有 8 vCPU 及 8 GB\n                RAM 来和其他四个 VM 对齐。当所有六个镜像都在使用时（48 vCPU 及 46 GB RAM），ESX 服务器被分配了 150% 的能力。两个额外的 VM 创建了一个二级 CC 区域，并执行在两个 CC 区域之间的活动来创建在 ESX 服务器上的负载。这些活动包括导入、mklabel 及构建操作，并在测试期间持续运行。<\/p><p>在本案例的背景负载中有两台其他的 ClearCase 虚拟机组成：一台 VOB 服务器及一台 ClearCase 客户端来作为视图（view）和构建服务器，也同样执行 mklabel 和导入操作。一个专用的 1 GB 网络连接着这些服务器和其他镜像。<\/p><p>这一 ClearCase 测试环境是实际 ClearCase 开发 VOB 的一个备份。100 VOB 被散布到两台服务器上。10 个最高容量的 VOB 被托管在 VM 镜像（VOB 服务器）上。剩余的 90 个 VOB 被托管在一个分离的物理服务器上，在此服务器上还有许可证服务器（license server）和注册服务器（registry server）。<\/p><p>这一用于比较的工作负载仿真了在一个 12 小时的时间段内大约 250 个并发用户。背景工作负载由以下方面组成：<\/p><ul class=\"ibm-bullet-list\"><li>200 个 CCRC 用户每小时执行 15 次事务<\/li><li>50 个动态视图用户用户每小时执行 15 次事务<\/li><li>38 个持续 clearmake 构建运行在 12 个不同的额外构建主机上（Unix 及 Windows）<\/li><li>1 台独立的 Unix 客户端运行集成任务<\/li><\/ul><h5 id=\"Table2\">表 2. 两个 ESX 服务器配置<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th> 配置 A<br /> （运行 100% 能力的 ESX 服务器）<\/th><th> 配置 B<br /> （运行 150% 能力的 ESX 服务器）<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td> ESX 服务器 <br />(32 vCPU，32 GB RAM) <\/td><td> 服务器托管 4 个镜像: <ul class=\"ibm-bullet-list\"><li>1 台 VOB 服务器<\/li><li>1 台 CCRC 服务器<\/li><li>2 台“贪婪”服务器<\/li><\/ul><\/td><td> 服务器托管 6 个镜像: <ul class=\"ibm-bullet-list\"><li>1 台 VOB 服务器<\/li><li>1 台 CCRC 服务器<\/li><li>2 台“贪婪”服务器<\/li><li>2 台 CC 服务器在分离的区域<\/li><\/ul><\/td><\/tr><\/tbody><\/table><p>图 1 比较了两个配置在超过 12 个小时的平均相应时间。相比配置 A，对于基本 ClearCase 操作配置 B 慢了 35%，UCM 操作慢了 25%。构建时间也慢了 22%。<\/p><h5 id=\"fig01\">图 1. 比较两种 ClearCase 环境<\/h5><img alt=\"当 ESX 服务器能力被分配在 150% 时 ClearCase 慢了\" src=\"/sunshine_new/images/1555978846/image001.jpg\" width=\"815\" /><p><strong>进一步探讨关联性和预订<\/strong><\/p><p>在第 1 部分，我们定义了关联性来作为在一台虚拟机上专用一个或更多资源的能力，这些资源来自虚拟机管理程序的相应资源。在一些虚拟机管理程序中，还有预订（reservation）的概念。预订在含义上与我们用来表达关联性的概念相一致。在这些系统中关联性标志着更多的是一个 VM 的 CPU 可以恰好指派给多少个物理核心。如果您指派您的专用 VM 到特定的 CPU，您也应同样分配您其余的 VM 到不同的 CPU 上。具有 CPU 关联性的 VM 或许性能更糟糕，因为他们也许无法被安排到多线程任务上。<\/p><p>我们建议 VM 拥有对虚拟机管理程序专用资源的访问。对于虚拟机管理程序是超线程，或者虚拟机管理程序被设计用于执行资源的自动化加载平衡的情形，还有一些额外的概念需要记住。<\/p><h3 id=\"2.1.CPUaffinityconsiderations|outline\">CPU 关联性注意事项<\/h3><p>如果使用 CPU 关联性，考虑以下问题：<\/p><ul class=\"ibm-bullet-list\"><li>如果您的虚拟机管理程序使用自动化加载平衡，CPU 关联性将会阻止虚拟机管理程序有效地工作。<\/li><li>在一个 VM 上的 CPU 关联性可能会阻止同一个虚拟机管理程序上的其他 VM 虚拟机管理程序。<\/li><li>在从一个虚拟机管理程序上将一个具有 CPU 关联性的 VM 移动到另外一个虚拟机管理程序上时，有可能会需要不同的处理器配置。<\/li><li>在多核或超线程机器上的 CPU 关联性将有可能阻止 VM 安排多线程任务，因为它对指定核心的请求是有限的。<\/li><\/ul><h2 id=\"summaryandconclusions\">总结和结论<\/h2><p>这一由两部分组成的系列文章探讨了虚拟化的优点和缺点，并使用了两个特定于 IBM Rational 产品的示例。<\/p><p>在第 1 部分中，我们覆盖了四个重要的维度，这些参数在使用虚拟化时必须被恰好判断：CPU、内存、磁盘 I/O 和存储，以及网络。我们强调了关联性（专用资源）的重要性，以及演示了当资源被过度承诺时有可能会发生的情况。<\/p><p>我们还提供了关于管理较差的虚拟化可能会大幅影响 IBM Rational 产品性能的示例。我们也展示了两个案例，其中的 IBM Rational Team Concert 和 IBM Rational ClearCase 当它们被托管在没有配置关联性，配置较差的虚拟环境上时性能很糟糕。<\/p><p>在第 2 部分中，我们更深入地了解了对过度承诺的权衡。<\/p><p>根据我们测试 IBM Rational 产品以及我们以往建议客户的经验，我们提供了建议和提示，故障排除策略和特定用户的示例，来帮助管理您的虚拟化基础设施。故障排除情形和建议可以从 <a href=\"https://jazz.net/wiki/bin/view/Deployment/VirtualizationTroubleshooting\">jazz.net Deployment wiki<\/a> 上看到。<\/p><h3 id=\"3.1.Virtualization’skeyadvantages|outline\">虚拟化的关键优势<\/h3><ul class=\"ibm-bullet-list\"><li>当前市场上所提供的硬件倾向于使它们自身更好地被分割和被虚拟机管理程序所使用，来托管多虚拟机。这些新机器节省空间和电力消耗，而且更加有效利用资源。<\/li><li>虚拟化基础设施可以增加部署新 VM 的速度（复制已有的 VM 或新的可立即使用的 VM）。<\/li><li>高可用（High-availability，HA）以及灾难恢复（Disaster Recovery，DR）解决方案可以与虚拟化一起集成，来获得更完整和有效成本的企业级配置。然而，需要注意的是，在一个单独的虚拟机管理程序上托管多个 VM 可能会导致一个单点失败。您可以了解这一特定领域，并使用 SAN 或 NAS 存储来为 VM 镜像和/或在一个备用的虚拟机管理程序上部署已准备要用的 VM。<\/li><li>VM 及它们的虚拟机管理程序可以从任何地点通过终端被管理（而不仅仅是在一个实验室中），从而可以优化和减少管理成本。<\/li><\/ul><p>了解完所给出关于较差管理的虚拟化可能出现的陷阱，您可能仍旧疑问这是否真的值得投资和劳神。但答案是非常值得！虚拟化是一个值得的投资，但我们也强调，虚拟化必须被恰当管理。在一些组织里，虚拟化是必然和永久的。消失的是专用的物理硬件、专用于托管一个单独应用的单台服务器。那些硬件厂商都在趋向于生产能增加更多处理器和内存的平台，切分新的硬件给虚拟机是最佳的方式来确保资源的有效性。<\/p><h3 id=\"3.2.Keyprinciplesdiscussedinthisseries|outline\">这一系列所讨论的关键原则<\/h3><ul class=\"ibm-bullet-list\"><li>尽可能分配 CPU、内存和网络作为专用资源。确保可以通过专用的 I/O 访问充足的共用存储。<\/li><li>只要可能，考虑 CPU 及内存关联性。在某些案例中，这将导致同一台主机上的其他 VM 性能变差。在某些案例中，虚拟机管理程序会作为集群的一部分，牵制资源可能会阻止整个家族的 VM 得以优化运行。这些是针对所有 VM 在 CPU 和内存资源无法被专用或预订时的一些性能权衡策略。<\/li><li>只要可能，通过监管资源消耗来管理您的虚拟化资源。了解有哪些其他的产品被托管在同一台 VM 上，以及那些被同一个虚拟机管理程序所托管的其它 VM 在做些什么。<\/li><li>只要可能，避免资源过度承诺。也就是说，任何 VM 或 VM 组合的资源永远不应超过虚拟机管理程序的物理资源。<\/li><li>如果您怀疑有与虚拟化相关的问题，收集关于 VM 配置、虚拟机管理程序和其他被同一个虚拟机管理程序托管的 VM 的特定数据。避免有偏见的信息，并使用脚本来收集特定，也许是定期的度量信息。<\/li><\/ul><h3 id=\"3.3.SpecialIBMRationalproductconsiderations|outline\">IBM Rational 产品应特别考虑的因素<\/h3><p>不同的软件产品的表现很不同。在某一个 VM 上的某一个产品上使用得很好虚拟化参数不一定对其他的产品有效。在这一系列文章中，我们检验了 Rational Team Concert 及 Rational ClearCase。其他 Rational 产品也许会表现得类似，也或许完全不同，这就是我们强调要理解虚拟化的各个关键维度的原因。<\/p><p>例如复杂多层应用程序，例如 Rational 协作化生命周期管理（Rational Collaborative Lifecycle Management）产品或 Rational ClearCase 要求就近访问专用资源。我们曾一起工作过的客户就曾遇到过由于并未强制执行上诉所列出的关键原则，而导致其在虚拟环境中的 Rational 产品性能很差的情形。<\/p><h2 id=\"creditsandacknowledgements\">致谢<\/h2><p>本文作者感谢我们的同事 Tim Lee、Chetna Warade、David Schlegel、Paul Weiss、Matthias Lee、Samir Shah、Harry Abadi 及 Poornima Seetharamaiah，我们在 Rational 支持和开发团队的同事，以及我们在 Intel、NetApp 和 VMware 的业务合作伙伴。<\/p><CMA ID: 974968><Site ID: 10><XSLT stylesheet used to transform this file: dw-document-html-7.0.xsl>\r\n\r\n\r\n<\/div>\r\n<\/div>\r\n","createTime":"2014-06-19 00:00:00","deployTime":"2014-06-19 00:00:00","id":0,"intro":"如果您目前正在 IBM Rational 软件上使用虚拟化方法，是否一切都像您预期的一样顺利？三位 IBM 专家将介绍 Rational 视角下的虚拟化，以及虚拟化环境从 Rational 应用程序中获取最优性能的关键要求。在第 2 部分，他们将展现更多的案例及和故障排除技巧。","keyword":"","recommend":false,"source":"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-2/index.html","title":"利用虚拟化成就智慧: 第 2 部分 使用 IBM 软件的最佳实践","typeId":0,"updateTime":"2014-06-19 00:00:00"}
{"author":"","clickNumber":0,"content":"\r\n<div class=\"ibm-columns\">\r\n<div class=\"ibm-col-1-1\">\r\n\r\n<div class=\"dw-sidebar ibm-inset\"><h2 id=\"N10073\">虚拟化的四个维度<\/h2><p>CPU<br />内存<br />磁盘输入/输出（I/O）及存储<br />网络<\/p><\/div><p>这个由两部分组成的系列文章将通过具体示例探讨虚拟化的优缺点。在<a href=\"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-1/\">第 1 部分<\/a>中，我们将从总体上解释虚拟化，尤其是它与 IBM Rational 软件的关系。我们将覆盖虚拟化的四个维度，CPU、内存、磁盘输入/输出（I/O）及存储、网络等应如何通过关联性（专用资源）被恰当地管理而不会过度承诺。我们所给出的例子展示了被恰当管理的虚拟化是如何彻底影响  IBM&#174; Rational&#174; 产品。尤其是我们所展示的两个案例分析，其中的 IBM&#174; Rational Team Concert&#8482; 及 IBM&#174; Rational&#174; ClearCase&#174; 托管在没有关联性配置的虚拟机中，虚拟环境配置欠佳，从而使之性能糟糕。<\/p><p>在第 2 部分中，我们将更加深入探究针对过度承诺的折中考虑。基于我们在 Rational 产品和曾服务客户身上测试得来的经验，我们将提供建议和技巧，故障排除和特定于供应商的示例来帮助您更好地管理您的虚拟化基础设施。所有提及的故障排除场景和建议都来自 <a href=\"https://jazz.net/wiki/bin/view/Deployment/VirtualizationTroubleshooting\">jazz.net Deployment wiki<\/a>。<\/p><h2 id=\"casestudyno3\">案例分析 3. 结合 ClearCase\n                探索过度承诺（overcommitment）<\/h2><p>案例分析 2 演示了当托管在没有专用资源的虚拟机（VM）上时，IBM Rational ClearCase 是如何糟糕。我们建议要为 IBM Rational 产品配置关联性和专用资源，来避免可能存在的过度承诺。然而，我们也认识到受管理的过度承诺对于虚拟化而言仍然具有显著的价值。案例分析 3 着眼于不同程度的过度承诺。<\/p><p>在我们其中之一的测试中，我们考察了一台拥有 4 个八核 CPU 及 64 GB内存的 Intel Westmere-EX 服务器。这台服务器启用了超线程，对于虚拟机管理程序（hypervisor）而言，这台拥有 32 个核心的服务器就如同拥有 64 个逻辑处理器（64 vCPU）。ClearCase CM 服务器安装在其中一个拥有 4 vCPU 和 8 GB RAM 的 VM 上，但没有专用资源或关联性。<\/p><p>在同一个虚拟机管理程序上我们还创建了 96 个拥有 4 vCPU 和 4 GB RAM 的 VM（64-位 RHEL 5.5）。这些 96 个镜像被用于产生背景负载。这 96 个镜像被组织成六组 16 VM 群组。每一个 16-VM 群组包括 64 vCPU 和 64 GB RAM，这与 Westmere-EX 自身的硬件维度是相符合的。因此每一个 16-VM 群组都 100%　体现了 Westmere-EX 服务器的硬件配给。<\/p><p>为了捕获基线平均响应时间数据（如表 1 a 行所示），我们仿真了 100 个用户的 UCM 负载并传递给 ClearCase CM 服务器。所有六组\n                VM 则处于挂起状态。<\/p><p>在下一个测试（表 1 中 b 行到 g 行），我们使用了六组 16 VM 的群组来创建背景负载。每一个 VM 都托管一个本机程序，运行多线程的平方根数学计算并分配了内存。这一“贪婪”程序确保每一个 VM 客户端将会 100% 消耗为它分配的处理器和内存。每一个测试以 16 个 VM 或 100% 相应的 Westmere-EX 服务器物理硬件为单位增加背景负载。<\/p><p>行 b 显示了 100 个用户 CC CM 服务器测试的平均响应时间数据，以及相应的 100% 的 Westmere-EX 负载（一组 16 VM 都运行“贪婪”程序）。行 c 到行 g 显示了 100 用户 CC CM 服务器测试随着逐步增加每一组 16 VM 的平均响应时间数据（每一步都逐步增加 100% 相应的 Westmere-EX 服务器负载）。<\/p><p>行 g 显示了在所有 96 个 VM 都在运行“贪婪”程序，即 600% 物理 Westmere-EX 服务器容量的情况下，我们的 100 个用户 CC CM 服务器测试的平均响应时间。响应时间非常糟糕。我们过度承诺的服务器无法在合理的响应时间内为 100 个用户 CC 负载提供服务。<\/p><p>让我们的服务器保证合理的性能的唯一办法是运行在一个具有专用资源的 VM 上。行 h 显示了与行 g 相同的测试，但 CC CM 服务器具有关联性和专用资源。在 600% 的负载下，CC CM 服务器以可接受的性能进行了响应。<\/p><h5 id=\"Table1\">表 1：使用 ClearCase 来展示关联性效果的性能测试<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"9 column table with heading row and center-aligned content\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th>a<br />物理机器<\/th><th>b<br />100% 无关联性的负载<\/th><th>c<br />200% 无关联性的负载<\/th><th>d<br />300% 无关联性的负载<\/th><th>e<br />400% 无关联性的负载<\/th><th>f<br />500% 无关联性的负载<\/th><th>g<br />600% 无关联性的负载<\/th><th>h<br />600% 有关联性的负载<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td><strong>产生流<\/strong><\/td><td><strong>1.03<\/strong><\/td><td> 1.57 <\/td><td><strong>1.87<\/strong><\/td><td> 3.48 <\/td><td> 29.81 <\/td><td> 39.76 <\/td><td> 153.29 <\/td><td><strong>1.88<\/strong><\/td><\/tr><tr><td><strong>产生活动<\/strong><\/td><td><strong>0.33<\/strong><\/td><td> 0.50 <\/td><td><strong>0.55<\/strong><\/td><td> 1.64 <\/td><td> 24.84 <\/td><td> 44.35 <\/td><td> 176.21 <\/td><td><strong>0.61<\/strong><\/td><\/tr><tr><td><strong>集活动<\/strong><\/td><td><strong>0.59<\/strong><\/td><td> 0.92 <\/td><td><strong>1.04<\/strong><\/td><td> 3.59 <\/td><td> 68.55 <\/td><td> 69.45 <\/td><td> 159.14 <\/td><td><strong>0.99<\/strong><\/td><\/tr><tr><td><strong>产生目录<\/strong><\/td><td><strong>1.98<\/strong><\/td><td> 2.78 <\/td><td><strong>3.04<\/strong><\/td><td> 4.93 <\/td><td> 64.72 <\/td><td> 70.43 <\/td><td> 161.33 <\/td><td><strong>3.35<\/strong><\/td><\/tr><tr><td><strong>检出目录<\/strong><\/td><td><strong>0.72<\/strong><\/td><td> 0.91 <\/td><td><strong>0.97<\/strong><\/td><td> 2.08 <\/td><td> 30.82 <\/td><td> 38.17 <\/td><td> 125.30 <\/td><td><strong>1.12<\/strong><\/td><\/tr><tr><td><strong>检入目录<\/strong><\/td><td><strong>0.61<\/strong><\/td><td> 0.78 <\/td><td><strong>0.82<\/strong><\/td><td> 1.35 <\/td><td> 11.86 <\/td><td> 13.73 <\/td><td> 68.03 <\/td><td><strong>0.91<\/strong><\/td><\/tr><tr><td><strong>产生文件<\/strong><\/td><td><strong>1.40<\/strong><\/td><td> 1.78 <\/td><td><strong>1.93<\/strong><\/td><td> 3.23 <\/td><td> 33.10 <\/td><td> 37.54 <\/td><td> 95.58 <\/td><td><strong>2.28<\/strong><\/td><\/tr><tr><td><strong>检出文件<\/strong><\/td><td><strong>0.91<\/strong><\/td><td> 1.25 <\/td><td><strong>1.45<\/strong><\/td><td> 1.51 <\/td><td> 3.81 <\/td><td> 5.42 <\/td><td> 68.12 <\/td><td><strong>1.47<\/strong><\/td><\/tr><\/tbody><\/table><p>这个例子展示了多个情况。没有关联性，产品的性能会大幅度降低到不可用的程度。更进一步，仅仅拥有 CC CM 服务器访问权限的 ClearCase 管理员无法理解甚至无法猜测究竟发生了什么情况。这个背景负载也许过于极端，但非常清晰地演示了过度承诺的影响。<\/p><p>不过，虚拟化并不是一个无助的命题。比较表 1 中的 c 和 h 行，这两行显示了 CC CM 服务器在没有关联性而虚拟机管理程序承担 200% 负载时，以及 CC CM 服务器有关联性而虚拟机管理程序承担 200% 负载时的情形。两种情形相似的响应时间足以表明，如果不可能有专用资源时虚拟机管理程序的能力无法承担超过 200% 负载，而对于资源有关联性的配置则可以提供可接受的响应时间。这个事实表明，如果管理得当的话，过度承诺可以成为一个切实可行的选择。<\/p><h2 id=\"casestudyno4\">案例分析 4. 过度承诺或低于承诺：性能 vs. 能力<\/h2><p>案例分析 4 比较了两个不同 VM 配置在同一台 ESX 服务器，即一台 32 vCPU 及 32 GB RAM 的 Intel SandyBridge 服务器（E5-2680 @\n                2.70GHz）上时 ClearCase 的响应时间。配置 A 使用了 100% 的 VMware ESX 的能力，而配置 B 则使用了 150%。<\/p><p>在配置 A 中，ESX 服务器托管 VOB 服务器，一个 ClearCase Remote Client（CCRC）服务器以及两个 VM 运行案例 3 中描述的“贪婪”程序。每一个 ESX 服务器上的 VM 运行 RHEL 5.6，并分配了 8 vCPU 和 8 GB RAM。配置 A 拥有  100% 专用的 ESX 硬件资源。<\/p><p>配置 B 使用配置 A 相同的四个 VM；不过，额外的两个 VM 被增加到 ESX 服务器上。这两个额外的 VM 具有 8 vCPU 及 8 GB\n                RAM 来和其他四个 VM 对齐。当所有六个镜像都在使用时（48 vCPU 及 46 GB RAM），ESX 服务器被分配了 150% 的能力。两个额外的 VM 创建了一个二级 CC 区域，并执行在两个 CC 区域之间的活动来创建在 ESX 服务器上的负载。这些活动包括导入、mklabel 及构建操作，并在测试期间持续运行。<\/p><p>在本案例的背景负载中有两台其他的 ClearCase 虚拟机组成：一台 VOB 服务器及一台 ClearCase 客户端来作为视图（view）和构建服务器，也同样执行 mklabel 和导入操作。一个专用的 1 GB 网络连接着这些服务器和其他镜像。<\/p><p>这一 ClearCase 测试环境是实际 ClearCase 开发 VOB 的一个备份。100 VOB 被散布到两台服务器上。10 个最高容量的 VOB 被托管在 VM 镜像（VOB 服务器）上。剩余的 90 个 VOB 被托管在一个分离的物理服务器上，在此服务器上还有许可证服务器（license server）和注册服务器（registry server）。<\/p><p>这一用于比较的工作负载仿真了在一个 12 小时的时间段内大约 250 个并发用户。背景工作负载由以下方面组成：<\/p><ul class=\"ibm-bullet-list\"><li>200 个 CCRC 用户每小时执行 15 次事务<\/li><li>50 个动态视图用户用户每小时执行 15 次事务<\/li><li>38 个持续 clearmake 构建运行在 12 个不同的额外构建主机上（Unix 及 Windows）<\/li><li>1 台独立的 Unix 客户端运行集成任务<\/li><\/ul><h5 id=\"Table2\">表 2. 两个 ESX 服务器配置<\/h5><table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" class=\"ibm-data-table\" summary=\"\"><thead xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><th>&#160;<\/th><th> 配置 A<br /> （运行 100% 能力的 ESX 服务器）<\/th><th> 配置 B<br /> （运行 150% 能力的 ESX 服务器）<\/th><\/tr><\/thead><tbody xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"><tr><td> ESX 服务器 <br />(32 vCPU，32 GB RAM) <\/td><td> 服务器托管 4 个镜像: <ul class=\"ibm-bullet-list\"><li>1 台 VOB 服务器<\/li><li>1 台 CCRC 服务器<\/li><li>2 台“贪婪”服务器<\/li><\/ul><\/td><td> 服务器托管 6 个镜像: <ul class=\"ibm-bullet-list\"><li>1 台 VOB 服务器<\/li><li>1 台 CCRC 服务器<\/li><li>2 台“贪婪”服务器<\/li><li>2 台 CC 服务器在分离的区域<\/li><\/ul><\/td><\/tr><\/tbody><\/table><p>图 1 比较了两个配置在超过 12 个小时的平均相应时间。相比配置 A，对于基本 ClearCase 操作配置 B 慢了 35%，UCM 操作慢了 25%。构建时间也慢了 22%。<\/p><h5 id=\"fig01\">图 1. 比较两种 ClearCase 环境<\/h5><img alt=\"当 ESX 服务器能力被分配在 150% 时 ClearCase 慢了\" src=\"/sunshine_new/images/1555978846/image001.jpg\" width=\"815\" /><p><strong>进一步探讨关联性和预订<\/strong><\/p><p>在第 1 部分，我们定义了关联性来作为在一台虚拟机上专用一个或更多资源的能力，这些资源来自虚拟机管理程序的相应资源。在一些虚拟机管理程序中，还有预订（reservation）的概念。预订在含义上与我们用来表达关联性的概念相一致。在这些系统中关联性标志着更多的是一个 VM 的 CPU 可以恰好指派给多少个物理核心。如果您指派您的专用 VM 到特定的 CPU，您也应同样分配您其余的 VM 到不同的 CPU 上。具有 CPU 关联性的 VM 或许性能更糟糕，因为他们也许无法被安排到多线程任务上。<\/p><p>我们建议 VM 拥有对虚拟机管理程序专用资源的访问。对于虚拟机管理程序是超线程，或者虚拟机管理程序被设计用于执行资源的自动化加载平衡的情形，还有一些额外的概念需要记住。<\/p><h3 id=\"2.1.CPUaffinityconsiderations|outline\">CPU 关联性注意事项<\/h3><p>如果使用 CPU 关联性，考虑以下问题：<\/p><ul class=\"ibm-bullet-list\"><li>如果您的虚拟机管理程序使用自动化加载平衡，CPU 关联性将会阻止虚拟机管理程序有效地工作。<\/li><li>在一个 VM 上的 CPU 关联性可能会阻止同一个虚拟机管理程序上的其他 VM 虚拟机管理程序。<\/li><li>在从一个虚拟机管理程序上将一个具有 CPU 关联性的 VM 移动到另外一个虚拟机管理程序上时，有可能会需要不同的处理器配置。<\/li><li>在多核或超线程机器上的 CPU 关联性将有可能阻止 VM 安排多线程任务，因为它对指定核心的请求是有限的。<\/li><\/ul><h2 id=\"summaryandconclusions\">总结和结论<\/h2><p>这一由两部分组成的系列文章探讨了虚拟化的优点和缺点，并使用了两个特定于 IBM Rational 产品的示例。<\/p><p>在第 1 部分中，我们覆盖了四个重要的维度，这些参数在使用虚拟化时必须被恰好判断：CPU、内存、磁盘 I/O 和存储，以及网络。我们强调了关联性（专用资源）的重要性，以及演示了当资源被过度承诺时有可能会发生的情况。<\/p><p>我们还提供了关于管理较差的虚拟化可能会大幅影响 IBM Rational 产品性能的示例。我们也展示了两个案例，其中的 IBM Rational Team Concert 和 IBM Rational ClearCase 当它们被托管在没有配置关联性，配置较差的虚拟环境上时性能很糟糕。<\/p><p>在第 2 部分中，我们更深入地了解了对过度承诺的权衡。<\/p><p>根据我们测试 IBM Rational 产品以及我们以往建议客户的经验，我们提供了建议和提示，故障排除策略和特定用户的示例，来帮助管理您的虚拟化基础设施。故障排除情形和建议可以从 <a href=\"https://jazz.net/wiki/bin/view/Deployment/VirtualizationTroubleshooting\">jazz.net Deployment wiki<\/a> 上看到。<\/p><h3 id=\"3.1.Virtualization’skeyadvantages|outline\">虚拟化的关键优势<\/h3><ul class=\"ibm-bullet-list\"><li>当前市场上所提供的硬件倾向于使它们自身更好地被分割和被虚拟机管理程序所使用，来托管多虚拟机。这些新机器节省空间和电力消耗，而且更加有效利用资源。<\/li><li>虚拟化基础设施可以增加部署新 VM 的速度（复制已有的 VM 或新的可立即使用的 VM）。<\/li><li>高可用（High-availability，HA）以及灾难恢复（Disaster Recovery，DR）解决方案可以与虚拟化一起集成，来获得更完整和有效成本的企业级配置。然而，需要注意的是，在一个单独的虚拟机管理程序上托管多个 VM 可能会导致一个单点失败。您可以了解这一特定领域，并使用 SAN 或 NAS 存储来为 VM 镜像和/或在一个备用的虚拟机管理程序上部署已准备要用的 VM。<\/li><li>VM 及它们的虚拟机管理程序可以从任何地点通过终端被管理（而不仅仅是在一个实验室中），从而可以优化和减少管理成本。<\/li><\/ul><p>了解完所给出关于较差管理的虚拟化可能出现的陷阱，您可能仍旧疑问这是否真的值得投资和劳神。但答案是非常值得！虚拟化是一个值得的投资，但我们也强调，虚拟化必须被恰当管理。在一些组织里，虚拟化是必然和永久的。消失的是专用的物理硬件、专用于托管一个单独应用的单台服务器。那些硬件厂商都在趋向于生产能增加更多处理器和内存的平台，切分新的硬件给虚拟机是最佳的方式来确保资源的有效性。<\/p><h3 id=\"3.2.Keyprinciplesdiscussedinthisseries|outline\">这一系列所讨论的关键原则<\/h3><ul class=\"ibm-bullet-list\"><li>尽可能分配 CPU、内存和网络作为专用资源。确保可以通过专用的 I/O 访问充足的共用存储。<\/li><li>只要可能，考虑 CPU 及内存关联性。在某些案例中，这将导致同一台主机上的其他 VM 性能变差。在某些案例中，虚拟机管理程序会作为集群的一部分，牵制资源可能会阻止整个家族的 VM 得以优化运行。这些是针对所有 VM 在 CPU 和内存资源无法被专用或预订时的一些性能权衡策略。<\/li><li>只要可能，通过监管资源消耗来管理您的虚拟化资源。了解有哪些其他的产品被托管在同一台 VM 上，以及那些被同一个虚拟机管理程序所托管的其它 VM 在做些什么。<\/li><li>只要可能，避免资源过度承诺。也就是说，任何 VM 或 VM 组合的资源永远不应超过虚拟机管理程序的物理资源。<\/li><li>如果您怀疑有与虚拟化相关的问题，收集关于 VM 配置、虚拟机管理程序和其他被同一个虚拟机管理程序托管的 VM 的特定数据。避免有偏见的信息，并使用脚本来收集特定，也许是定期的度量信息。<\/li><\/ul><h3 id=\"3.3.SpecialIBMRationalproductconsiderations|outline\">IBM Rational 产品应特别考虑的因素<\/h3><p>不同的软件产品的表现很不同。在某一个 VM 上的某一个产品上使用得很好虚拟化参数不一定对其他的产品有效。在这一系列文章中，我们检验了 Rational Team Concert 及 Rational ClearCase。其他 Rational 产品也许会表现得类似，也或许完全不同，这就是我们强调要理解虚拟化的各个关键维度的原因。<\/p><p>例如复杂多层应用程序，例如 Rational 协作化生命周期管理（Rational Collaborative Lifecycle Management）产品或 Rational ClearCase 要求就近访问专用资源。我们曾一起工作过的客户就曾遇到过由于并未强制执行上诉所列出的关键原则，而导致其在虚拟环境中的 Rational 产品性能很差的情形。<\/p><h2 id=\"creditsandacknowledgements\">致谢<\/h2><p>本文作者感谢我们的同事 Tim Lee、Chetna Warade、David Schlegel、Paul Weiss、Matthias Lee、Samir Shah、Harry Abadi 及 Poornima Seetharamaiah，我们在 Rational 支持和开发团队的同事，以及我们在 Intel、NetApp 和 VMware 的业务合作伙伴。<\/p><CMA ID: 974968><Site ID: 10><XSLT stylesheet used to transform this file: dw-document-html-7.0.xsl>\r\n\r\n\r\n<\/div>\r\n<\/div>\r\n","createTime":"2014-06-19 00:00:00","deployTime":"2014-06-19 00:00:00","id":0,"intro":"如果您目前正在 IBM Rational 软件上使用虚拟化方法，是否一切都像您预期的一样顺利？三位 IBM 专家将介绍 Rational 视角下的虚拟化，以及虚拟化环境从 Rational 应用程序中获取最优性能的关键要求。在第 2 部分，他们将展现更多的案例及和故障排除技巧。","keyword":"","recommend":false,"source":"http://www.ibm.com/developerworks/cn/rational/smart-virtualization-2/index.html","title":"利用虚拟化成就智慧: 第 2 部分 使用 IBM 软件的最佳实践","typeId":0,"updateTime":"2014-06-19 00:00:00"}
